{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjrvEctReNOtJAbuHF+HCt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohsenh17/jaxLearning/blob/main/flax/CustomMetrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUAfhJeb-vgD",
        "outputId": "c8b44554-07a8-4d00-f1b4-bdef37b8eb44",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: orbax in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.35)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax) (1.1.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax) (0.2.4)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax) (0.6.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.68)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax) (13.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax) (6.0.2)\n",
            "Requirement already satisfied: jaxlib<=0.4.35,>=0.4.34 in /usr/local/lib/python3.10/dist-packages (from jax) (0.4.35)\n",
            "Requirement already satisfied: ml-dtypes>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from jax) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax) (1.13.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.4.0)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.10.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (4.25.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (2.18.0)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (0.1.87)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.87->optax->flax) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (3.21.0)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade flax orbax jax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "from flax import nnx\n",
        "import jax.numpy as jnp\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import orbax.checkpoint as ocp\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import io\n",
        "\n"
      ],
      "metadata": {
        "id": "JFO7NNqQ_Dtc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate a dataset with 100 samples, 10 features, 5 informative, 5 redundant, and 2 classes\n",
        "X, y = make_classification(n_samples=10000, n_features=10, n_informative=8,\n",
        "                          n_classes=2, random_state=42)\n",
        "df = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
        "df['Class'] = y\n",
        "csv_data = df.to_csv(index=True)\n"
      ],
      "metadata": {
        "id": "W4I2hnqUodtF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Class for Custom  Data\n",
        "This section defines a CustomDataset class, which inherits from torch.utils.data.Dataset. It is designed to load and preprocess data from a CSV file for machine learning tasks.\n",
        "\n",
        "python\n",
        "Copy code\n"
      ],
      "metadata": {
        "id": "UJReXJOQliDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    # Initialize the dataset by loading, scaling, and organizing features and labels\n",
        "    def __init__(self, dataset, transform=None, target_transform=None):\n",
        "        # Load the CSV file into a DataFrame, using the first column as the index\n",
        "        completeDF = pd.read_csv(dataset, index_col=0)\n",
        "\n",
        "        # Extract the 'Class' column as labels\n",
        "        self.labels = pd.DataFrame(completeDF['Class'])\n",
        "\n",
        "        # Extract all other columns as features, excluding 'Class'\n",
        "        features_raw = pd.DataFrame(completeDF.drop('Class', axis=1))\n",
        "\n",
        "        # Scale the feature values to the range [0, 1] using Min-Max Scaling\n",
        "        scaler = MinMaxScaler()\n",
        "        self.features = pd.DataFrame(scaler.fit_transform(features_raw))\n",
        "\n",
        "        # Assign optional transformations for features and labels\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    # Return the total number of data samples in the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    # Retrieve a specific sample by index and apply transformations if needed\n",
        "    def __getitem__(self, idx):\n",
        "        # Extract feature values as a NumPy array for the given index\n",
        "        features = np.array(self.features.iloc[idx, :])\n",
        "\n",
        "        # Extract the corresponding label for the given index\n",
        "        label = self.labels.iloc[idx, 0]\n",
        "\n",
        "        # Apply transformation to the features, if provided\n",
        "        if self.transform:\n",
        "            features = self.transform(features)\n",
        "\n",
        "        # Apply transformation to the label, if provided\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        # Return the processed features and label\n",
        "        return features, label\n"
      ],
      "metadata": {
        "id": "ZBPFELboo4e1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"mssmartypants/rice-type-classification\")\n",
        "print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWv5r05xBvNk",
        "outputId": "5770b688-d563-4c4d-d317-195f89d99d34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mssmartypants/rice-type-classification?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 888k/888k [00:00<00:00, 82.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "/root/.cache/kagglehub/datasets/mssmartypants/rice-type-classification/versions/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /root/.cache/kagglehub/datasets/mssmartypants/rice-type-classification/versions/2/\n",
        "! mv /root/.cache/kagglehub/datasets/mssmartypants/rice-type-classification/versions/2/riceClassification.csv riceClassification.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXec3_GJByPc",
        "outputId": "e4ff98c8-b20f-44e2-eab4-43530c234301"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "riceClassification.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = CustomImageDataset(dataset=io.StringIO(csv_data))\n",
        "dataset = CustomImageDataset(dataset=\"riceClassification.csv\")\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [.9, 0.05,0.05])\n",
        "data_loader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
        "\n",
        "for features, labels in data_loader:\n",
        "    print(\"Batch of features has shape: \",features.shape)\n",
        "    print(\"Batch of labels has shape: \", labels.shape)\n",
        "    print(features)\n",
        "    print(labels)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s3fFrv-otNR",
        "outputId": "faa13b12-eeb0-4404-c35e-4703eb113ffa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch of features has shape:  torch.Size([4, 10])\n",
            "Batch of labels has shape:  torch.Size([4])\n",
            "tensor([[0.1755, 0.2035, 0.3720, 0.5619, 0.1643, 0.2361, 0.4173, 0.1383, 0.9166,\n",
            "         0.1892],\n",
            "        [0.4437, 0.7472, 0.3068, 0.9379, 0.4140, 0.5274, 0.8995, 0.4691, 0.6280,\n",
            "         0.7074],\n",
            "        [0.5336, 0.7536, 0.4296, 0.8934, 0.5008, 0.6132, 0.2992, 0.4980, 0.6802,\n",
            "         0.5794],\n",
            "        [0.8529, 0.7759, 0.8213, 0.7178, 0.8035, 0.8867, 0.7210, 0.5935, 0.8323,\n",
            "         0.3089]], dtype=torch.float64)\n",
            "tensor([1, 1, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Implementation\n",
        "This section implements a customizable MLP model with dropout and batch normalization at each layer. The architecture is parameterized by input dimensions, hidden dimensions, and the number of classes"
      ],
      "metadata": {
        "id": "ZpJhAZGomiBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nnx.Module):\n",
        "    def __init__(self, din, dm1, dm2, dm3, num_classes: int, rngs: nnx.Rngs):\n",
        "        # Define dropout, linear, and batch normalization layers for each stage\n",
        "        self.dp1 = nnx.Dropout(rate=0.4, rngs=rngs)\n",
        "        self.linear1 = nnx.Linear(din, dm1, rngs=rngs)\n",
        "        self.bn1 = nnx.BatchNorm(dm1, rngs=rngs)\n",
        "\n",
        "        self.dp2 = nnx.Dropout(rate=0.2, rngs=rngs)\n",
        "        self.linear2 = nnx.Linear(dm1, dm2, rngs=rngs)\n",
        "        self.bn2 = nnx.BatchNorm(dm2, rngs=rngs)\n",
        "\n",
        "        self.dp3 = nnx.Dropout(rate=0.1, rngs=rngs)\n",
        "        self.linear3 = nnx.Linear(dm2, dm3, rngs=rngs)\n",
        "        self.bn3 = nnx.BatchNorm(dm3, rngs=rngs)\n",
        "\n",
        "        # Output layer without batch normalization\n",
        "        self.linear4 = nnx.Linear(dm3, num_classes, rngs=rngs)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # Apply dropout, linear transformation, activation, and batch normalization for each layer\n",
        "        x = self.dp1(x)\n",
        "        x = self.linear1(x)\n",
        "        x = nnx.gelu(x)\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        x = self.dp2(x)\n",
        "        x = self.linear2(x)\n",
        "        x = nnx.gelu(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        x = self.dp3(x)\n",
        "        x = self.linear3(x)\n",
        "        x = nnx.gelu(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        # Final linear transformation\n",
        "        x = self.linear4(x)\n",
        "\n",
        "        # Sigmoid activation for binary classification (uncomment if needed)\n",
        "        # return nnx.sigmoid(x)\n",
        "        return x\n",
        "# Instantiate the model with given dimensions\n",
        "model = MLP(din=10, dm1=16, dm2=32, dm3=16, num_classes=1, rngs=nnx.Rngs(0))\n",
        "\n",
        "# Test the model with a sample input tensor of shape (3, 10)\n",
        "y = model(x=jnp.ones((3, 10)))\n",
        "\n",
        "# Display the model architecture and output\n",
        "nnx.display(model)\n",
        "nnx.display(y)\n",
        "\n",
        "# Output the predictions\n",
        "print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C2PTOR3_Abz",
        "outputId": "b73c0d9f-09c5-4198-a4f8-3f1e05bde157",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  dp1=Dropout(rate=0.4, broadcast_dims=(), deterministic=False, rng_collection='dropout', rngs=Rngs(\n",
            "    default=RngStream(\n",
            "      key=RngKey(\n",
            "        value=Array((), dtype=key<fry>) overlaying:\n",
            "        [0 0],\n",
            "        tag='default'\n",
            "      ),\n",
            "      count=RngCount(\n",
            "        value=Array(17, dtype=uint32),\n",
            "        tag='default'\n",
            "      )\n",
            "    )\n",
            "  )),\n",
            "  linear1=Linear(\n",
            "    kernel=Param(\n",
            "      value=Array(shape=(10, 16), dtype=float32)\n",
            "    ),\n",
            "    bias=Param(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    in_features=10,\n",
            "    out_features=16,\n",
            "    use_bias=True,\n",
            "    dtype=None,\n",
            "    param_dtype=<class 'jax.numpy.float32'>,\n",
            "    precision=None,\n",
            "    kernel_init=<function variance_scaling.<locals>.init at 0x7b832bb0dbd0>,\n",
            "    bias_init=<function zeros at 0x7b832c5dc280>,\n",
            "    dot_general=<function dot_general at 0x7b832cd195a0>\n",
            "  ),\n",
            "  bn1=BatchNorm(\n",
            "    mean=BatchStat(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    var=BatchStat(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    scale=Param(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    bias=Param(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    num_features=16,\n",
            "    use_running_average=False,\n",
            "    axis=-1,\n",
            "    momentum=0.99,\n",
            "    epsilon=1e-05,\n",
            "    dtype=None,\n",
            "    param_dtype=<class 'jax.numpy.float32'>,\n",
            "    use_bias=True,\n",
            "    use_scale=True,\n",
            "    bias_init=<function zeros at 0x7b832c5dc280>,\n",
            "    scale_init=<function ones at 0x7b832c5dc430>,\n",
            "    axis_name=None,\n",
            "    axis_index_groups=None,\n",
            "    use_fast_variance=True\n",
            "  ),\n",
            "  dp2=Dropout(rate=0.2, broadcast_dims=(), deterministic=False, rng_collection='dropout', rngs=Rngs(...)),\n",
            "  linear2=Linear(\n",
            "    kernel=Param(\n",
            "      value=Array(shape=(16, 32), dtype=float32)\n",
            "    ),\n",
            "    bias=Param(\n",
            "      value=Array(shape=(32,), dtype=float32)\n",
            "    ),\n",
            "    in_features=16,\n",
            "    out_features=32,\n",
            "    use_bias=True,\n",
            "    dtype=None,\n",
            "    param_dtype=<class 'jax.numpy.float32'>,\n",
            "    precision=None,\n",
            "    kernel_init=<function variance_scaling.<locals>.init at 0x7b832bb0dbd0>,\n",
            "    bias_init=<function zeros at 0x7b832c5dc280>,\n",
            "    dot_general=<function dot_general at 0x7b832cd195a0>\n",
            "  ),\n",
            "  bn2=BatchNorm(\n",
            "    mean=BatchStat(\n",
            "      value=Array(shape=(32,), dtype=float32)\n",
            "    ),\n",
            "    var=BatchStat(\n",
            "      value=Array(shape=(32,), dtype=float32)\n",
            "    ),\n",
            "    scale=Param(\n",
            "      value=Array(shape=(32,), dtype=float32)\n",
            "    ),\n",
            "    bias=Param(\n",
            "      value=Array(shape=(32,), dtype=float32)\n",
            "    ),\n",
            "    num_features=32,\n",
            "    use_running_average=False,\n",
            "    axis=-1,\n",
            "    momentum=0.99,\n",
            "    epsilon=1e-05,\n",
            "    dtype=None,\n",
            "    param_dtype=<class 'jax.numpy.float32'>,\n",
            "    use_bias=True,\n",
            "    use_scale=True,\n",
            "    bias_init=<function zeros at 0x7b832c5dc280>,\n",
            "    scale_init=<function ones at 0x7b832c5dc430>,\n",
            "    axis_name=None,\n",
            "    axis_index_groups=None,\n",
            "    use_fast_variance=True\n",
            "  ),\n",
            "  dp3=Dropout(rate=0.1, broadcast_dims=(), deterministic=False, rng_collection='dropout', rngs=Rngs(...)),\n",
            "  linear3=Linear(\n",
            "    kernel=Param(\n",
            "      value=Array(shape=(32, 16), dtype=float32)\n",
            "    ),\n",
            "    bias=Param(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    in_features=32,\n",
            "    out_features=16,\n",
            "    use_bias=True,\n",
            "    dtype=None,\n",
            "    param_dtype=<class 'jax.numpy.float32'>,\n",
            "    precision=None,\n",
            "    kernel_init=<function variance_scaling.<locals>.init at 0x7b832bb0dbd0>,\n",
            "    bias_init=<function zeros at 0x7b832c5dc280>,\n",
            "    dot_general=<function dot_general at 0x7b832cd195a0>\n",
            "  ),\n",
            "  bn3=BatchNorm(\n",
            "    mean=BatchStat(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    var=BatchStat(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    scale=Param(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    bias=Param(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    num_features=16,\n",
            "    use_running_average=False,\n",
            "    axis=-1,\n",
            "    momentum=0.99,\n",
            "    epsilon=1e-05,\n",
            "    dtype=None,\n",
            "    param_dtype=<class 'jax.numpy.float32'>,\n",
            "    use_bias=True,\n",
            "    use_scale=True,\n",
            "    bias_init=<function zeros at 0x7b832c5dc280>,\n",
            "    scale_init=<function ones at 0x7b832c5dc430>,\n",
            "    axis_name=None,\n",
            "    axis_index_groups=None,\n",
            "    use_fast_variance=True\n",
            "  ),\n",
            "  linear4=Linear(\n",
            "    kernel=Param(\n",
            "      value=Array(shape=(16, 1), dtype=float32)\n",
            "    ),\n",
            "    bias=Param(\n",
            "      value=Array([0.], dtype=float32)\n",
            "    ),\n",
            "    in_features=16,\n",
            "    out_features=1,\n",
            "    use_bias=True,\n",
            "    dtype=None,\n",
            "    param_dtype=<class 'jax.numpy.float32'>,\n",
            "    precision=None,\n",
            "    kernel_init=<function variance_scaling.<locals>.init at 0x7b832bb0dbd0>,\n",
            "    bias_init=<function zeros at 0x7b832c5dc280>,\n",
            "    dot_general=<function dot_general at 0x7b832cd195a0>\n",
            "  )\n",
            ")\n",
            "[[-0.46538347]\n",
            " [-0.11259228]\n",
            " [ 0.57797575]]\n",
            "[[-0.46538347]\n",
            " [-0.11259228]\n",
            " [ 0.57797575]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Metrics"
      ],
      "metadata": {
        "id": "1Mxqo-0MoVSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomMetrics(nnx.metrics.Metric):\n",
        "    def __init__(self):\n",
        "        # Initialize counters for true positives, false positives, and false negatives\n",
        "        self.true_positives = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "        self.false_positives = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "        self.false_negatives = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "\n",
        "    def update(self, loss, logits, labels):\n",
        "        \"\"\"\n",
        "        Update the metric counters based on the predictions and labels.\n",
        "        Assumes logits are probabilities (e.g., from a sigmoid activation).\n",
        "        \"\"\"\n",
        "        # Convert logits to binary predictions\n",
        "        predictions = jnp.where(jnp.array(logits) > 0.5, 1, 0)\n",
        "\n",
        "        predictions = predictions.ravel()\n",
        "        labels = jnp.array(labels).ravel()\n",
        "\n",
        "\n",
        "        # Compute metrics\n",
        "        tp = jnp.sum((labels == 1) & (predictions == 1))\n",
        "        fp = jnp.sum((labels == 0) & (predictions == 1))\n",
        "        fn = jnp.sum((labels == 1) & (predictions == 0))\n",
        "\n",
        "        # Update counters\n",
        "        self.true_positives += tp\n",
        "        self.false_positives += fp\n",
        "        self.false_negatives += fn\n",
        "\n",
        "    def compute(self):\n",
        "        \"\"\"\n",
        "        Compute precision, recall, and F1-score from the accumulated counters.\n",
        "        \"\"\"\n",
        "        precision = self.true_positives / (self.true_positives + self.false_positives + 1e-7)\n",
        "        recall = self.true_positives / (self.true_positives + self.false_negatives + 1e-7)\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
        "        return {\"f1_score\": f1_score, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset the metric counters.\n",
        "        \"\"\"\n",
        "        self.true_positives = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "        self.false_positives = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "        self.false_negatives = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n"
      ],
      "metadata": {
        "id": "mLuplI5goY_D"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomAccuracy(nnx.metrics.Metric):\n",
        "    def __init__(self):\n",
        "        self.correct_count= nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "        self.total_count= nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "\n",
        "    def update(self, loss, logits, labels):\n",
        "        # Convert logits to binary predictions (0 or 1) based on a 0.5 threshold\n",
        "        predictions = jnp.where(jnp.array(logits) > 0.5, 1, 0)\n",
        "        # Flatten if necessary\n",
        "        predictions = predictions.ravel()\n",
        "        labels = jnp.array(labels).ravel()\n",
        "\n",
        "        # Calculate number of correct predictions in the current batch\n",
        "        self.correct_count += jnp.sum(predictions == labels)\n",
        "        self.total_count += len(labels)\n",
        "\n",
        "    def compute(self):\n",
        "        # Calculate accuracy over all batches seen so far\n",
        "        if self.total_count == 0:\n",
        "            return 0  # Avoid division by zero if no samples are seen\n",
        "        return self.correct_count / self.total_count\n",
        "    def reset(self):\n",
        "        # Reset counters\n",
        "        self.correct_count = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "        self.total_count = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))"
      ],
      "metadata": {
        "id": "B1kVQ_DFIQQh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test class"
      ],
      "metadata": {
        "id": "nlXFKOWbps1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = CustomMetrics()\n",
        "logits = jnp.array([0.9, 0.7, 0.2, 0.4, 0.8, 0.1])\n",
        "labels = jnp.array([1, 1, 0, 0, 1, 0])\n",
        "\n",
        "metric.update(None, logits, labels)\n",
        "metrics = metric.compute()\n",
        "\n",
        "print(metrics[\"precision\"], 1)\n",
        "print(metrics[\"recall\"], 1)\n",
        "print(metrics[\"f1_score\"], 1)\n",
        "\n",
        "metric.reset()\n",
        "\n",
        "logits = jnp.array([0.9, 0.7, 0.2, 0.8, 0.1, 0.3])\n",
        "labels = jnp.array([1, 0, 1, 1, 0, 0])\n",
        "\n",
        "# Expected binary predictions: [1, 1, 0, 1, 0, 0]\n",
        "# TP = 2 (Correct positive predictions: [1, 1])\n",
        "# FP = 1 (False positive prediction: [1])\n",
        "# FN = 1 (False negative prediction: [1])\n",
        "metric.update(None, logits, labels)\n",
        "metrics = metric.compute()\n",
        "\n",
        "expected_precision = 2 / (2 + 1)  # TP / (TP + FP)\n",
        "expected_recall = 2 / (2 + 1)     # TP / (TP + FN)\n",
        "expected_f1 = 2 * (expected_precision * expected_recall) / (expected_precision + expected_recall)\n",
        "\n",
        "print(metrics[\"precision\"], expected_precision)\n",
        "print(metrics[\"recall\"], expected_recall)\n",
        "print(metrics[\"f1_score\"], expected_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlUoD37jprj3",
        "outputId": "64a20821-9e38-41a9-c5cc-5af03bd95018"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 1\n",
            "1.0 1\n",
            "1.0 1\n",
            "0.6666667 0.6666666666666666\n",
            "0.6666667 0.6666666666666666\n",
            "0.6666666 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up an Optimizer and Metrics"
      ],
      "metadata": {
        "id": "BFME6UD3m88I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Optax for optimizer configuration\n",
        "import optax\n",
        "\n",
        "# Learning rate and momentum for the optimizer\n",
        "learning_rate = 0.005\n",
        "momentum = 0.9\n",
        "\n",
        "# Instantiate the MLP model\n",
        "model = MLP(10, 16, 32, 16, 1, rngs=nnx.Rngs(0))\n",
        "\n",
        "# Set up the optimizer using Adam with the specified learning rate\n",
        "optimizer = nnx.Optimizer(model, optax.adam(learning_rate))\n",
        "\n",
        "# Initialize metrics for tracking training performance\n",
        "metrics = nnx.MultiMetric(\n",
        "    accuracy=CustomAccuracy(),\n",
        "    f1_precision_recall=CustomMetrics(),\n",
        "    loss=nnx.metrics.Average('loss'),  # Tracks the average loss\n",
        ")\n"
      ],
      "metadata": {
        "id": "ASj5AcVZqpXN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Defining Loss, Training, and Evaluation Functions"
      ],
      "metadata": {
        "id": "thvdNah4nV8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(model: MLP, batch):\n",
        "    # Forward pass: Compute logits (raw predictions) using the model\n",
        "    logits = model(batch['features'])\n",
        "\n",
        "    # Compute binary cross-entropy loss for classification\n",
        "    loss = optax.sigmoid_binary_cross_entropy(\n",
        "        logits=logits, labels=batch['labels'].reshape(-1, 1)\n",
        "    ).mean()\n",
        "\n",
        "    # Optionally, use a custom loss function like mean squared error\n",
        "    # loss = (logits - batch['labels'])**2\n",
        "\n",
        "    # Return the computed loss and logits\n",
        "    return loss, logits\n",
        "@nnx.jit\n",
        "def train_step(model: MLP, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
        "    \"\"\"Train for a single step.\"\"\"\n",
        "    # Compute loss and gradients using a differentiable function\n",
        "    grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
        "    (loss, logits), grads = grad_fn(model, batch)\n",
        "\n",
        "    # Update metrics in-place with loss and logits\n",
        "    metrics.update(loss=loss, logits=logits, labels=batch['labels'])\n",
        "\n",
        "    # Apply the computed gradients to update model parameters\n",
        "    optimizer.update(grads)\n",
        "\n",
        "    # Return the loss and logits after applying sigmoid for interpretation\n",
        "    return loss, nnx.sigmoid(logits)\n",
        "@nnx.jit\n",
        "def eval_step(model: MLP, metrics: nnx.MultiMetric, batch):\n",
        "    # Compute loss and logits for the batch\n",
        "    loss, logits = loss_fn(model, batch)\n",
        "\n",
        "    # Update metrics in-place with evaluation results\n",
        "    metrics.update(loss=loss, logits=logits, labels=batch['labels'])\n",
        "\n",
        "    # Return the loss for further aggregation or monitoring\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "HsPjwULJq8GS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Preparation and DataLoader Creation"
      ],
      "metadata": {
        "id": "p6jJmprenxrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch):\n",
        "    # Transpose batch to group features and labels separately\n",
        "    transposed_data = list(zip(*batch))\n",
        "\n",
        "    # Convert labels and features into NumPy arrays\n",
        "    labels = np.array(transposed_data[1])\n",
        "    features = np.array(transposed_data[0])\n",
        "\n",
        "    # Return a dictionary with features and labels\n",
        "    return {\"features\": features, \"labels\": labels}\n",
        "\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [0.7, 0.1, 0.2])\n",
        "\n",
        "train_ds = DataLoader(train_set, batch_size=64, shuffle=True, drop_last=True, collate_fn=custom_collate_fn)\n",
        "val_ds = DataLoader(val_set, batch_size=64, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
        "test_ds = DataLoader(test_set, batch_size=64, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
        "\n",
        "# Fetch a single batch from the training DataLoader\n",
        "batch_data = next(iter(train_ds))\n",
        "imgs = batch_data['features']\n",
        "lbls = batch_data['labels']\n",
        "\n",
        "# Print shapes and data types for verification\n",
        "print(imgs.shape, imgs[0].dtype, lbls.shape, lbls[0].dtype)\n",
        "print(lbls)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fioF1mHarC8_",
        "outputId": "eea59058-e5af-4c13-a148-bcd45b79cd35"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10) float64 (64,) int64\n",
            "[0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0\n",
            " 1 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 1 1 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint! save model"
      ],
      "metadata": {
        "id": "U4eF72y2q150"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "from orbax.checkpoint.type_handlers import TypeHandler\n",
        "from orbax.checkpoint.type_handlers import register_type_handler\n",
        "from copy import deepcopy\n",
        "state_org = 0\n",
        "def process_and_save_model_state(model, ckpt_dir):\n",
        "    \"\"\"\n",
        "    Processes the model state, modifies the PRNG key, and saves the state to a checkpoint directory.\n",
        "\n",
        "    Args:\n",
        "        model: The model whose state is being processed.\n",
        "        ckpt_dir (str): Directory to save the checkpoint.\n",
        "    \"\"\"\n",
        "    # Retrieve the model's state\n",
        "    state = nnx.state(model)\n",
        "\n",
        "    # Split the model into parameters and state\n",
        "    _, state = nnx.split(model)\n",
        "\n",
        "    # Deep copy the state\n",
        "    state_org = deepcopy(state)\n",
        "\n",
        "    # Display the current state (for inspection)\n",
        "    #nnx.display(state)\n",
        "\n",
        "    # Modify the PRNG key for 'dp1'\n",
        "    prng_key_value = state[\"dp1\"][\"rngs\"][\"default\"][\"key\"].value\n",
        "    state[\"dp1\"][\"rngs\"][\"default\"][\"key\"] = nnx.VariableState(\n",
        "        type=nnx.Param,\n",
        "        value=jax.random.key_data(prng_key_value),\n",
        "        tag='default'\n",
        "    )\n",
        "    #print(prng_key_value)\n",
        "    # Create a new empty checkpoint directory\n",
        "    ckpt_dir = ocp.test_utils.erase_and_create_empty(ckpt_dir)\n",
        "\n",
        "    # Initialize the checkpointing system\n",
        "    checkpointer = ocp.PyTreeCheckpointer()\n",
        "\n",
        "    # Save the modified state to the checkpoint directory\n",
        "    checkpointer.save(f'{ckpt_dir}/state', state)\n",
        "    return state_org, prng_key_value\n",
        "\n",
        "# Example usage\n",
        "#model = ...  # Initialize your model\n",
        "ckpt_dir = '/content/my-checkpoints/'  # Specify your checkpoint directory\n",
        "state_org, prng_key_value = process_and_save_model_state(model, ckpt_dir)\n",
        "#process_and_save_model_state(model, ckpt_dir)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jeAzhDPJYSIp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop for Neural Network with Metrics Tracking"
      ],
      "metadata": {
        "id": "HN4uqJhHok23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "\n",
        "def update_metrics_history(metrics_history, prefix, metrics):\n",
        "    \"\"\"\n",
        "    Updates the metrics history dictionary with the computed metrics for a given phase.\n",
        "\n",
        "    Args:\n",
        "        metrics_history (dict): Dictionary to store metrics over epochs.\n",
        "        prefix (str): Prefix for metric keys (e.g., 'train', 'val', 'test').\n",
        "        metrics (object): Metrics object with `compute` method returning metric values.\n",
        "    \"\"\"\n",
        "    for metric, value in metrics.compute().items():\n",
        "        if metric == 'f1_precision_recall':\n",
        "            metrics_history[f'{prefix}_f1_score'].append(value['f1_score'])\n",
        "            metrics_history[f'{prefix}_precision'].append(value['precision'])\n",
        "            metrics_history[f'{prefix}_recall'].append(value['recall'])\n",
        "        else:\n",
        "            metrics_history[f'{prefix}_{metric}'].append(value)\n",
        "\n",
        "def log_metrics(epoch, num_epochs, metrics_history, prefix):\n",
        "    \"\"\"\n",
        "    Logs the metrics for a given phase (train, val) in the current epoch.\n",
        "\n",
        "    Args:\n",
        "        epoch (int): Current epoch number.\n",
        "        num_epochs (int): Total number of epochs.\n",
        "        metrics_history (dict): Dictionary containing historical metrics.\n",
        "        prefix (str): Prefix for metric keys (e.g., 'train', 'val').\n",
        "    \"\"\"\n",
        "    print(\n",
        "        f\"[{prefix}] epoch: {epoch + 1}/{num_epochs}, \"\n",
        "        f\"loss: {metrics_history[f'{prefix}_loss'][-1]:.4f}, \"\n",
        "        f\"accuracy: {metrics_history[f'{prefix}_accuracy'][-1]:.4f}, \"\n",
        "        f\"precision: {metrics_history[f'{prefix}_precision'][-1]:.4f}, \"\n",
        "        f\"recall: {metrics_history[f'{prefix}_recall'][-1]:.4f}, \"\n",
        "        f\"f1_score: {metrics_history[f'{prefix}_f1_score'][-1]:.4f}, \"\n",
        "    )\n",
        "\n",
        "def train_and_evaluate(model, optimizer, train_ds, val_ds, metrics, num_epochs, tracking_metric, patience, mode='min'):\n",
        "    \"\"\"\n",
        "    Trains and evaluates the model while tracking and logging metrics.\n",
        "\n",
        "    Args:\n",
        "        model: Model to train.\n",
        "        optimizer: Optimizer for model training.\n",
        "        train_ds: Training dataset.\n",
        "        val_ds: Validation dataset.\n",
        "        metrics: Metrics object to track performance.\n",
        "        num_epochs (int): Number of training epochs.\n",
        "        tracking_metric (str): Metric to track for early stopping.\n",
        "        patience (int): Number of epochs to wait without improvement before stopping.\n",
        "    \"\"\"\n",
        "    metrics_history = {\n",
        "        'train_loss': [], 'train_accuracy': [], 'train_precision': [],\n",
        "        'train_recall': [], 'train_f1_score': [], 'val_loss': [],\n",
        "        'val_accuracy': [], 'val_precision': [], 'val_recall': [],\n",
        "        'val_f1_score': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        for batch in train_ds:\n",
        "            loss, logits = train_step(model, optimizer, metrics, batch)\n",
        "        update_metrics_history(metrics_history, 'train', metrics)\n",
        "        metrics.reset()  # Reset metrics after training\n",
        "        log_metrics(epoch, num_epochs, metrics_history, 'train')\n",
        "\n",
        "        # Validation phase\n",
        "        for batch in val_ds:\n",
        "            loss = eval_step(model, metrics, batch)\n",
        "        update_metrics_history(metrics_history, 'val', metrics)\n",
        "        metrics.reset()  # Reset metrics after validation\n",
        "        log_metrics(epoch, num_epochs, metrics_history, 'val')\n",
        "        if mode == 'max':\n",
        "          if metrics_history[tracking_metric][-1] == max(metrics_history[tracking_metric]):\n",
        "              print('saving model')\n",
        "              ckpt_dir = '/content/my-checkpoints/'  # Specify your checkpoint directory\n",
        "              #process_and_save_model_state(model, ckpt_dir)\n",
        "              state_org, prng_key_value = process_and_save_model_state(model, ckpt_dir)\n",
        "          elif len(metrics_history[tracking_metric]) - np.argmax(metrics_history[tracking_metric]) > patience:\n",
        "              print('early stopping')\n",
        "              return metrics_history, state_org, prng_key_value\n",
        "\n",
        "\n",
        "    return metrics_history, state_org, prng_key_value\n",
        "\n",
        "# Example usage\n",
        "num_epochs = 50\n",
        "tracking_metric = 'val_accuracy'\n",
        "patience = 3\n",
        "mode = 'max'\n",
        "metrics_history, state_org, prng_key_value = train_and_evaluate(model, optimizer, train_ds, val_ds, metrics, num_epochs, tracking_metric, patience, mode=mode)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_cxxkNtrH0O",
        "outputId": "dd53a529-a0c9-4acb-90a8-3b037282afef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] epoch: 1/50, loss: 0.3701, accuracy: 0.8123, precision: 0.8598, recall: 0.7847, f1_score: 0.8205, \n",
            "[val] epoch: 1/50, loss: 0.2033, accuracy: 0.9051, precision: 0.9531, recall: 0.8730, f1_score: 0.9113, \n",
            "saving model\n",
            "[train] epoch: 2/50, loss: 0.1745, accuracy: 0.9261, precision: 0.9432, recall: 0.9202, f1_score: 0.9315, \n",
            "[val] epoch: 2/50, loss: 0.1364, accuracy: 0.9453, precision: 0.9630, recall: 0.9380, f1_score: 0.9504, \n",
            "saving model\n",
            "[train] epoch: 3/50, loss: 0.1452, accuracy: 0.9412, precision: 0.9541, recall: 0.9377, f1_score: 0.9458, \n",
            "[val] epoch: 3/50, loss: 0.1370, accuracy: 0.9386, precision: 0.9626, recall: 0.9260, f1_score: 0.9439, \n",
            "[train] epoch: 4/50, loss: 0.1245, accuracy: 0.9524, precision: 0.9610, recall: 0.9517, f1_score: 0.9563, \n",
            "[val] epoch: 4/50, loss: 0.1191, accuracy: 0.9542, precision: 0.9665, recall: 0.9510, f1_score: 0.9587, \n",
            "saving model\n",
            "[train] epoch: 5/50, loss: 0.1227, accuracy: 0.9522, precision: 0.9614, recall: 0.9508, f1_score: 0.9561, \n",
            "[val] epoch: 5/50, loss: 0.1299, accuracy: 0.9492, precision: 0.9652, recall: 0.9430, f1_score: 0.9540, \n",
            "[train] epoch: 6/50, loss: 0.1223, accuracy: 0.9497, precision: 0.9598, recall: 0.9476, f1_score: 0.9537, \n",
            "[val] epoch: 6/50, loss: 0.1094, accuracy: 0.9581, precision: 0.9763, recall: 0.9480, f1_score: 0.9619, \n",
            "saving model\n",
            "[train] epoch: 7/50, loss: 0.1170, accuracy: 0.9531, precision: 0.9618, recall: 0.9521, f1_score: 0.9569, \n",
            "[val] epoch: 7/50, loss: 0.1353, accuracy: 0.9526, precision: 0.9645, recall: 0.9500, f1_score: 0.9572, \n",
            "[train] epoch: 8/50, loss: 0.1072, accuracy: 0.9577, precision: 0.9647, recall: 0.9577, f1_score: 0.9612, \n",
            "[val] epoch: 8/50, loss: 0.1218, accuracy: 0.9554, precision: 0.9646, recall: 0.9550, f1_score: 0.9598, \n",
            "[train] epoch: 9/50, loss: 0.1077, accuracy: 0.9578, precision: 0.9647, recall: 0.9579, f1_score: 0.9613, \n",
            "[val] epoch: 9/50, loss: 0.1096, accuracy: 0.9565, precision: 0.9714, recall: 0.9500, f1_score: 0.9606, \n",
            "early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction and Evaluation Pipeline"
      ],
      "metadata": {
        "id": "L0iX4KVcqTfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "@nnx.jit\n",
        "def pred_step(model: MLP, batch):\n",
        "    logits = model(batch['features'])\n",
        "    return nnx.sigmoid(logits)\n",
        "\n",
        "test_ds = DataLoader(test_set, batch_size=32, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
        "\n",
        "ypred = []  # List to store predicted probabilities\n",
        "label = []  # List to store true labels\n",
        "\n",
        "for test_batch in test_ds:\n",
        "    logits = pred_step(model, test_batch)\n",
        "    ypred.extend(np.ravel(logits))  # Flatten and collect predictions\n",
        "    label.extend(np.ravel(test_batch[\"labels\"]))  # Flatten and collect true labels\n",
        "\n",
        "binary_ypred = np.where(np.array(ypred) > 0.5, 1, 0)\n",
        "\n",
        "accuracy = sum([1 for pred, true in zip(binary_ypred, label) if pred == true]) / len(label)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JdDFipvrj4L",
        "outputId": "35d8c8c0-4b73-4465-adf1-b1e6ce0e7331"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing a New Model and Load!"
      ],
      "metadata": {
        "id": "GVyXqnLJrQF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def restore_model_and_initialize_optimizer(model_class, model_args, ckpt_dir, learning_rate):\n",
        "    \"\"\"\n",
        "    Restores a model's state from a checkpoint and initializes the optimizer.\n",
        "\n",
        "    Args:\n",
        "        model_class: The model class to instantiate (e.g., MLP).\n",
        "        model_args (tuple): Arguments for the model class initialization.\n",
        "        ckpt_dir (str): Directory of the checkpoint files.\n",
        "        learning_rate (float): Learning rate for the optimizer.\n",
        "\n",
        "    Returns:\n",
        "        tuple: The restored model, optimizer, and metrics object.\n",
        "    \"\"\"\n",
        "    # Step 1: Re-initialize the model\n",
        "    new_model = model_class(*model_args, rngs=nnx.Rngs(0))\n",
        "\n",
        "    # Step 2: Evaluate the abstract shape of the model and split into graph/state\n",
        "    abstract_model = nnx.eval_shape(lambda: new_model)\n",
        "    graph_def, abstract_state = nnx.split(abstract_model)\n",
        "\n",
        "    # Optional debug: Display abstract state\n",
        "    # print('The abstract NNX state (all leaves are abstract arrays):')\n",
        "    # nnx.display(abstract_state)\n",
        "\n",
        "    # Step 3: Restore the state from checkpoint\n",
        "    checkpointer = ocp.PyTreeCheckpointer()\n",
        "    state_restored = checkpointer.restore(f\"{ckpt_dir}/state\", abstract_state)\n",
        "\n",
        "    # Step 4: Modify the PRNG key value and ensure correct type\n",
        "    prng_key_value = state_restored[\"dp1\"][\"rngs\"][\"default\"][\"key\"].value\n",
        "    state_restored[\"dp1\"][\"rngs\"][\"default\"][\"key\"].value = jax.random.wrap_key_data(prng_key_value)\n",
        "\n",
        "\n",
        "    # Step 5: Validate restored state matches the original (optional)\n",
        "    # jax.tree_map(np.testing.assert_array_equal, state_org, state_restored)\n",
        "\n",
        "    # Step 6: Merge the graph definition with the restored state\n",
        "    restored_model = nnx.merge(graph_def, state_restored)\n",
        "\n",
        "    # Step 7: Initialize the optimizer\n",
        "    optimizer = nnx.Optimizer(restored_model, optax.adam(learning_rate))\n",
        "\n",
        "    # Step 8: Initialize metrics\n",
        "    metrics = nnx.MultiMetric(\n",
        "        loss=nnx.metrics.Average('loss')\n",
        "    )\n",
        "\n",
        "    return restored_model, optimizer, metrics\n",
        "\n",
        "# Example usage\n",
        "ckpt_dir = \"/content/my-checkpoints/\"\n",
        "learning_rate = 0.001\n",
        "model_args = (10, 16, 32, 16, 1)  # Example arguments for MLP\n",
        "\n",
        "restored_model, new_optimizer, new_metrics = restore_model_and_initialize_optimizer(\n",
        "    MLP, model_args, ckpt_dir, learning_rate\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sIjj6adSeQ88",
        "outputId": "756bf5da-eb19-490e-908c-b12f84eab2f6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/orbax/checkpoint/type_handlers.py:1330: UserWarning: Couldn't find sharding info under RestoreArgs. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file instead of directly from RestoreArgs. Note also that this option is unsafe when restoring on a different topology than the checkpoint was saved with.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train more if needed"
      ],
      "metadata": {
        "id": "t6s624pmsBwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "#model.train()\n",
        "metrics_history = {\n",
        "  'train_loss': [],\n",
        "  'train_accuracy': [],\n",
        "  'train_precision': [],\n",
        "  'train_recall': [],\n",
        "  'train_f1': [],\n",
        "  'val_loss': [],\n",
        "  'val_accuracy': [],\n",
        "  'val_precision': [],\n",
        "  'val_recall': [],\n",
        "  'val_f1': [],\n",
        "  'test_loss': [],\n",
        "  'test_accuracy': [],\n",
        "  'test_precision': [],\n",
        "  'test_recall': [],\n",
        "  'test_f1': [],\n",
        "}\n",
        "\n",
        "num_epochs = 40  # Number of training epochs\n",
        "for epoch in range(num_epochs):\n",
        "    # Train on each batch in the training dataset\n",
        "    for batch in train_ds:\n",
        "        loss, logits = train_step(model, optimizer, metrics, batch)\n",
        "\n",
        "    # Compute and log training metrics for this epoch\n",
        "    for metric, value in metrics.compute().items():\n",
        "        metrics_history[f'train_{metric}'].append(value)\n",
        "\n",
        "    # Reset metrics for the next epoch\n",
        "    metrics.reset()\n",
        "\n",
        "    # Log training performance\n",
        "    print(\n",
        "        f\"[train] epoch: {epoch + 1}/{num_epochs}, \"\n",
        "        f\"loss: {metrics_history['train_loss'][-1]:.4f}, \"\n",
        "    )\n",
        "\n",
        "# later stuff\n",
        "\"\"\"\n",
        "for batch in val_ds:\n",
        "    loss = eval_step(model, metrics, batch)\n",
        "\n",
        "for metric, value in metrics.compute().items():\n",
        "    metrics_history[f'val_{metric}'].append(value)\n",
        "\n",
        "metrics.reset()\n",
        "print(\n",
        "    f\"[val] epoch: {epoch + 1}/{num_epochs}, \"\n",
        "    f\"loss: {metrics_history['val_loss'][-1]:.4f}, \"\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"[train] epoch: {epoch + 1}/{num_epochs}, \"\n",
        "    f\"loss: {metrics_history['train_loss'][-1]:.4f}, \"\n",
        "    f\"accuracy: {metrics_history['train_accuracy'][-1]:.2f}\"\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "O8Ukn5kWrwut",
        "outputId": "8d2e4abc-b75d-47d3-a98a-f77740c89b16"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-87beb539a5a2>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Train on each batch in the training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-6c07f6b505a1>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Extract feature values as a NumPy array for the given index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Extract the corresponding label for the given index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6294\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6296\u001b[0;31m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_can_hold_identifiers_and_holds_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5446\u001b[0m         \"\"\"\n\u001b[1;32m   5447\u001b[0m         if (\n\u001b[0;32m-> 5448\u001b[0;31m             \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5449\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mis_string_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5450\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_object_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \"\"\"\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_is_dtype_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validate saved model"
      ],
      "metadata": {
        "id": "7qZ0YMvQsI5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "restored_model.eval()\n",
        "@nnx.jit\n",
        "def pred_step(model: MLP, batch):\n",
        "    logits = model(batch['features'])\n",
        "    return nnx.sigmoid(logits)\n",
        "\n",
        "test_ds = DataLoader(test_set, batch_size=32, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
        "\n",
        "ypred = []  # List to store predicted probabilities\n",
        "label = []  # List to store true labels\n",
        "\n",
        "for test_batch in test_ds:\n",
        "    logits = pred_step(restored_model, test_batch)\n",
        "    ypred.extend(np.ravel(logits))  # Flatten and collect predictions\n",
        "    label.extend(np.ravel(test_batch[\"labels\"]))  # Flatten and collect true labels\n",
        "\n",
        "binary_ypred = np.where(np.array(ypred) > 0.5, 1, 0)\n",
        "\n",
        "accuracy = sum([1 for pred, true in zip(binary_ypred, label) if pred == true]) / len(label)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqlRLOx02910",
        "outputId": "b59e35a4-9231-4aaf-cc6b-0a55ab6edf7e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7058\n"
          ]
        }
      ]
    }
  ]
}