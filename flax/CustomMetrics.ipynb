{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOen5MtZfEqPf1I5/fItyY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohsenh17/jaxLearning/blob/main/flax/CustomMetrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUAfhJeb-vgD",
        "outputId": "d00c2a21-8a07-444f-e0cf-d5ceeb0f5ef3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: orbax in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.35)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax) (1.1.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax) (0.2.4)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax) (0.6.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.68)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax) (13.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax) (6.0.2)\n",
            "Requirement already satisfied: jaxlib<=0.4.35,>=0.4.34 in /usr/local/lib/python3.10/dist-packages (from jax) (0.4.35)\n",
            "Requirement already satisfied: ml-dtypes>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from jax) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax) (1.13.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.4.0)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.10.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (4.25.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (2.18.0)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (0.1.87)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.87->optax->flax) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (3.21.0)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade flax orbax jax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "from flax import nnx\n",
        "import jax.numpy as jnp\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import orbax.checkpoint as ocp\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import io\n",
        "\n"
      ],
      "metadata": {
        "id": "JFO7NNqQ_Dtc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate a dataset with 100 samples, 10 features, 5 informative, 5 redundant, and 2 classes\n",
        "X, y = make_classification(n_samples=10000, n_features=10, n_informative=8,\n",
        "                          n_classes=2, random_state=42)\n",
        "df = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
        "df['Class'] = y\n",
        "csv_data = df.to_csv(index=True)\n"
      ],
      "metadata": {
        "id": "W4I2hnqUodtF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Class for Custom  Data\n",
        "This section defines a CustomDataset class, which inherits from torch.utils.data.Dataset. It is designed to load and preprocess data from a CSV file for machine learning tasks.\n",
        "\n",
        "python\n",
        "Copy code\n"
      ],
      "metadata": {
        "id": "UJReXJOQliDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    # Initialize the dataset by loading, scaling, and organizing features and labels\n",
        "    def __init__(self, dataset, transform=None, target_transform=None):\n",
        "        # Load the CSV file into a DataFrame, using the first column as the index\n",
        "        completeDF = pd.read_csv(dataset, index_col=0)\n",
        "\n",
        "        # Extract the 'Class' column as labels\n",
        "        self.labels = pd.DataFrame(completeDF['Class'])\n",
        "\n",
        "        # Extract all other columns as features, excluding 'Class'\n",
        "        features_raw = pd.DataFrame(completeDF.drop('Class', axis=1))\n",
        "\n",
        "        # Scale the feature values to the range [0, 1] using Min-Max Scaling\n",
        "        scaler = MinMaxScaler()\n",
        "        self.features = pd.DataFrame(scaler.fit_transform(features_raw))\n",
        "\n",
        "        # Assign optional transformations for features and labels\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    # Return the total number of data samples in the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    # Retrieve a specific sample by index and apply transformations if needed\n",
        "    def __getitem__(self, idx):\n",
        "        # Extract feature values as a NumPy array for the given index\n",
        "        features = np.array(self.features.iloc[idx, :])\n",
        "\n",
        "        # Extract the corresponding label for the given index\n",
        "        label = self.labels.iloc[idx, 0]\n",
        "\n",
        "        # Apply transformation to the features, if provided\n",
        "        if self.transform:\n",
        "            features = self.transform(features)\n",
        "\n",
        "        # Apply transformation to the label, if provided\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        # Return the processed features and label\n",
        "        return features, label\n"
      ],
      "metadata": {
        "id": "ZBPFELboo4e1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"mssmartypants/rice-type-classification\")\n",
        "print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWv5r05xBvNk",
        "outputId": "54c3bc27-16ef-4201-a7b1-34a69fba7e24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/mssmartypants/rice-type-classification/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /root/.cache/kagglehub/datasets/mssmartypants/rice-type-classification/versions/2/\n",
        "! mv /root/.cache/kagglehub/datasets/mssmartypants/rice-type-classification/versions/2/riceClassification.csv riceClassification.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXec3_GJByPc",
        "outputId": "47c150eb-6ecf-4620-e5d5-7232d2667c29"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/root/.cache/kagglehub/datasets/mssmartypants/rice-type-classification/versions/2/riceClassification.csv': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = CustomImageDataset(dataset=io.StringIO(csv_data))\n",
        "dataset = CustomImageDataset(dataset=\"riceClassification.csv\")\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [.9, 0.05,0.05])\n",
        "data_loader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
        "\n",
        "for features, labels in data_loader:\n",
        "    print(\"Batch of features has shape: \",features.shape)\n",
        "    print(\"Batch of labels has shape: \", labels.shape)\n",
        "    print(features)\n",
        "    print(labels)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s3fFrv-otNR",
        "outputId": "d7f1642c-7274-4b91-f52a-3bc5573a7734"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch of features has shape:  torch.Size([4, 10])\n",
            "Batch of labels has shape:  torch.Size([4])\n",
            "tensor([[0.4464, 0.7199, 0.3409, 0.9179, 0.4184, 0.5301, 0.7653, 0.4536, 0.6562,\n",
            "         0.6445],\n",
            "        [0.7972, 0.7674, 0.7494, 0.7517, 0.7394, 0.8419, 0.3968, 0.5646, 0.8317,\n",
            "         0.3451],\n",
            "        [0.1432, 0.4239, 0.1024, 0.9252, 0.1427, 0.1962, 0.3097, 0.2244, 0.6361,\n",
            "         0.6663],\n",
            "        [0.7786, 0.7595, 0.7281, 0.7587, 0.7265, 0.8267, 0.6643, 0.5578, 0.8260,\n",
            "         0.3531]], dtype=torch.float64)\n",
            "tensor([1, 0, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Implementation\n",
        "This section implements a customizable MLP model with dropout and batch normalization at each layer. The architecture is parameterized by input dimensions, hidden dimensions, and the number of classes"
      ],
      "metadata": {
        "id": "ZpJhAZGomiBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nnx.Module):\n",
        "    def __init__(self, din, dm1, dm2, dm3, num_classes: int, rngs: nnx.Rngs):\n",
        "        # Define dropout, linear, and batch normalization layers for each stage\n",
        "        self.dp1 = nnx.Dropout(rate=0.4, rngs=rngs)\n",
        "        self.linear1 = nnx.Linear(din, dm1, rngs=rngs)\n",
        "        self.bn1 = nnx.BatchNorm(dm1, rngs=rngs)\n",
        "\n",
        "        self.dp2 = nnx.Dropout(rate=0.2, rngs=rngs)\n",
        "        self.linear2 = nnx.Linear(dm1, dm2, rngs=rngs)\n",
        "        self.bn2 = nnx.BatchNorm(dm2, rngs=rngs)\n",
        "\n",
        "        self.dp3 = nnx.Dropout(rate=0.1, rngs=rngs)\n",
        "        self.linear3 = nnx.Linear(dm2, dm3, rngs=rngs)\n",
        "        self.bn3 = nnx.BatchNorm(dm3, rngs=rngs)\n",
        "\n",
        "        # Output layer without batch normalization\n",
        "        self.linear4 = nnx.Linear(dm3, num_classes, rngs=rngs)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # Apply dropout, linear transformation, activation, and batch normalization for each layer\n",
        "        x = self.dp1(x)\n",
        "        x = self.linear1(x)\n",
        "        x = nnx.gelu(x)\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        x = self.dp2(x)\n",
        "        x = self.linear2(x)\n",
        "        x = nnx.gelu(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        x = self.dp3(x)\n",
        "        x = self.linear3(x)\n",
        "        x = nnx.gelu(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        # Final linear transformation\n",
        "        x = self.linear4(x)\n",
        "\n",
        "        # Sigmoid activation for binary classification (uncomment if needed)\n",
        "        # return nnx.sigmoid(x)\n",
        "        return x\n",
        "# Instantiate the model with given dimensions\n",
        "model = MLP(din=10, dm1=16, dm2=32, dm3=16, num_classes=1, rngs=nnx.Rngs(0))\n",
        "\n",
        "# Test the model with a sample input tensor of shape (3, 10)\n",
        "y = model(x=jnp.ones((3, 10)))\n",
        "\n",
        "# Display the model architecture and output\n",
        "nnx.display(model)\n",
        "nnx.display(y)\n",
        "\n",
        "# Output the predictions\n",
        "print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C2PTOR3_Abz",
        "outputId": "f38dd069-75fd-4d7a-c8cf-c0e8d4dfc30b",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  dp1=Dropout(rate=0.4, broadcast_dims=(), deterministic=False, rng_collection='dropout', rngs=Rngs(\n",
            "    default=RngStream(\n",
            "      key=RngKey(\n",
            "        value=Array((), dtype=key<fry>) overlaying:\n",
            "        [0 0],\n",
            "        tag='default'\n",
            "      ),\n",
            "      count=RngCount(\n",
            "        value=Array(17, dtype=uint32),\n",
            "        tag='default'\n",
            "      )\n",
            "    )\n",
            "  )),\n",
            "  linear1=Linear(\n",
            "    kernel=Param(\n",
            "      value=Array(shape=(10, 16), dtype=float32)\n",
            "    ),\n",
            "    bias=Param(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    in_features=10,\n",
            "    out_features=16,\n",
            "    use_bias=True,\n",
            "    dtype=None,\n",
            "    param_dtype=<class 'jax.numpy.float32'>,\n",
            "    precision=None,\n",
            "    kernel_init=<function variance_scaling.<locals>.init at 0x7ebf078f3f40>,\n",
            "    bias_init=<function zeros at 0x7ebf07ff8dc0>,\n",
            "    dot_general=<function dot_general at 0x7ebf08925ea0>\n",
            "  ),\n",
            "  bn1=BatchNorm(\n",
            "    mean=BatchStat(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    var=BatchStat(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    scale=Param(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    bias=Param(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    num_features=16,\n",
            "    use_running_average=False,\n",
            "    axis=-1,\n",
            "    momentum=0.99,\n",
            "    epsilon=1e-05,\n",
            "    dtype=None,\n",
            "    param_dtype=<class 'jax.numpy.float32'>,\n",
            "    use_bias=True,\n",
            "    use_scale=True,\n",
            "    bias_init=<function zeros at 0x7ebf07ff8dc0>,\n",
            "    scale_init=<function ones at 0x7ebf07ff8f70>,\n",
            "    axis_name=None,\n",
            "    axis_index_groups=None,\n",
            "    use_fast_variance=True\n",
            "  ),\n",
            "  dp2=Dropout(rate=0.2, broadcast_dims=(), deterministic=False, rng_collection='dropout', rngs=Rngs(...)),\n",
            "  linear2=Linear(\n",
            "    kernel=Param(\n",
            "      value=Array(shape=(16, 32), dtype=float32)\n",
            "    ),\n",
            "    bias=Param(\n",
            "      value=Array(shape=(32,), dtype=float32)\n",
            "    ),\n",
            "    in_features=16,\n",
            "    out_features=32,\n",
            "    use_bias=True,\n",
            "    dtype=None,\n",
            "    param_dtype=<class 'jax.numpy.float32'>,\n",
            "    precision=None,\n",
            "    kernel_init=<function variance_scaling.<locals>.init at 0x7ebf078f3f40>,\n",
            "    bias_init=<function zeros at 0x7ebf07ff8dc0>,\n",
            "    dot_general=<function dot_general at 0x7ebf08925ea0>\n",
            "  ),\n",
            "  bn2=BatchNorm(\n",
            "    mean=BatchStat(\n",
            "      value=Array(shape=(32,), dtype=float32)\n",
            "    ),\n",
            "    var=BatchStat(\n",
            "      value=Array(shape=(32,), dtype=float32)\n",
            "    ),\n",
            "    scale=Param(\n",
            "      value=Array(shape=(32,), dtype=float32)\n",
            "    ),\n",
            "    bias=Param(\n",
            "      value=Array(shape=(32,), dtype=float32)\n",
            "    ),\n",
            "    num_features=32,\n",
            "    use_running_average=False,\n",
            "    axis=-1,\n",
            "    momentum=0.99,\n",
            "    epsilon=1e-05,\n",
            "    dtype=None,\n",
            "    param_dtype=<class 'jax.numpy.float32'>,\n",
            "    use_bias=True,\n",
            "    use_scale=True,\n",
            "    bias_init=<function zeros at 0x7ebf07ff8dc0>,\n",
            "    scale_init=<function ones at 0x7ebf07ff8f70>,\n",
            "    axis_name=None,\n",
            "    axis_index_groups=None,\n",
            "    use_fast_variance=True\n",
            "  ),\n",
            "  dp3=Dropout(rate=0.1, broadcast_dims=(), deterministic=False, rng_collection='dropout', rngs=Rngs(...)),\n",
            "  linear3=Linear(\n",
            "    kernel=Param(\n",
            "      value=Array(shape=(32, 16), dtype=float32)\n",
            "    ),\n",
            "    bias=Param(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    in_features=32,\n",
            "    out_features=16,\n",
            "    use_bias=True,\n",
            "    dtype=None,\n",
            "    param_dtype=<class 'jax.numpy.float32'>,\n",
            "    precision=None,\n",
            "    kernel_init=<function variance_scaling.<locals>.init at 0x7ebf078f3f40>,\n",
            "    bias_init=<function zeros at 0x7ebf07ff8dc0>,\n",
            "    dot_general=<function dot_general at 0x7ebf08925ea0>\n",
            "  ),\n",
            "  bn3=BatchNorm(\n",
            "    mean=BatchStat(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    var=BatchStat(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    scale=Param(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    bias=Param(\n",
            "      value=Array(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    num_features=16,\n",
            "    use_running_average=False,\n",
            "    axis=-1,\n",
            "    momentum=0.99,\n",
            "    epsilon=1e-05,\n",
            "    dtype=None,\n",
            "    param_dtype=<class 'jax.numpy.float32'>,\n",
            "    use_bias=True,\n",
            "    use_scale=True,\n",
            "    bias_init=<function zeros at 0x7ebf07ff8dc0>,\n",
            "    scale_init=<function ones at 0x7ebf07ff8f70>,\n",
            "    axis_name=None,\n",
            "    axis_index_groups=None,\n",
            "    use_fast_variance=True\n",
            "  ),\n",
            "  linear4=Linear(\n",
            "    kernel=Param(\n",
            "      value=Array(shape=(16, 1), dtype=float32)\n",
            "    ),\n",
            "    bias=Param(\n",
            "      value=Array([0.], dtype=float32)\n",
            "    ),\n",
            "    in_features=16,\n",
            "    out_features=1,\n",
            "    use_bias=True,\n",
            "    dtype=None,\n",
            "    param_dtype=<class 'jax.numpy.float32'>,\n",
            "    precision=None,\n",
            "    kernel_init=<function variance_scaling.<locals>.init at 0x7ebf078f3f40>,\n",
            "    bias_init=<function zeros at 0x7ebf07ff8dc0>,\n",
            "    dot_general=<function dot_general at 0x7ebf08925ea0>\n",
            "  )\n",
            ")\n",
            "[[-0.46538347]\n",
            " [-0.11259228]\n",
            " [ 0.57797575]]\n",
            "[[-0.46538347]\n",
            " [-0.11259228]\n",
            " [ 0.57797575]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Metrics"
      ],
      "metadata": {
        "id": "1Mxqo-0MoVSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomMetrics(nnx.metrics.Metric):\n",
        "    def __init__(self):\n",
        "        # Initialize counters for true positives, false positives, and false negatives\n",
        "        self.true_positives = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "        self.false_positives = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "        self.false_negatives = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "\n",
        "    def update(self, loss, logits, labels):\n",
        "        \"\"\"\n",
        "        Update the metric counters based on the predictions and labels.\n",
        "        Assumes logits are probabilities (e.g., from a sigmoid activation).\n",
        "        \"\"\"\n",
        "        # Convert logits to binary predictions\n",
        "        predictions = jnp.where(jnp.array(logits) > 0.5, 1, 0)\n",
        "\n",
        "        predictions = predictions.ravel()\n",
        "        labels = jnp.array(labels).ravel()\n",
        "\n",
        "\n",
        "        # Compute metrics\n",
        "        tp = jnp.sum((labels == 1) & (predictions == 1))\n",
        "        fp = jnp.sum((labels == 0) & (predictions == 1))\n",
        "        fn = jnp.sum((labels == 1) & (predictions == 0))\n",
        "\n",
        "        # Update counters\n",
        "        self.true_positives += tp\n",
        "        self.false_positives += fp\n",
        "        self.false_negatives += fn\n",
        "\n",
        "    def compute(self):\n",
        "        \"\"\"\n",
        "        Compute precision, recall, and F1-score from the accumulated counters.\n",
        "        \"\"\"\n",
        "        precision = self.true_positives / (self.true_positives + self.false_positives + 1e-7)\n",
        "        recall = self.true_positives / (self.true_positives + self.false_negatives + 1e-7)\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
        "        return {\"f1_score\": f1_score, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset the metric counters.\n",
        "        \"\"\"\n",
        "        self.true_positives = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "        self.false_positives = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "        self.false_negatives = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n"
      ],
      "metadata": {
        "id": "mLuplI5goY_D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomAccuracy(nnx.metrics.Metric):\n",
        "    def __init__(self):\n",
        "        self.correct_count= nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "        self.total_count= nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "\n",
        "    def update(self, loss, logits, labels):\n",
        "        # Convert logits to binary predictions (0 or 1) based on a 0.5 threshold\n",
        "        predictions = jnp.where(jnp.array(logits) > 0.5, 1, 0)\n",
        "        # Flatten if necessary\n",
        "        predictions = predictions.ravel()\n",
        "        labels = jnp.array(labels).ravel()\n",
        "\n",
        "        # Calculate number of correct predictions in the current batch\n",
        "        self.correct_count += jnp.sum(predictions == labels)\n",
        "        self.total_count += len(labels)\n",
        "\n",
        "    def compute(self):\n",
        "        # Calculate accuracy over all batches seen so far\n",
        "        if self.total_count == 0:\n",
        "            return 0  # Avoid division by zero if no samples are seen\n",
        "        return self.correct_count / self.total_count\n",
        "    def reset(self):\n",
        "        # Reset counters\n",
        "        self.correct_count = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))\n",
        "        self.total_count = nnx.metrics.MetricState(jnp.array(0, dtype=jnp.int32))"
      ],
      "metadata": {
        "id": "B1kVQ_DFIQQh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test class"
      ],
      "metadata": {
        "id": "nlXFKOWbps1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = CustomMetrics()\n",
        "logits = jnp.array([0.9, 0.7, 0.2, 0.4, 0.8, 0.1])\n",
        "labels = jnp.array([1, 1, 0, 0, 1, 0])\n",
        "\n",
        "metric.update(None, logits, labels)\n",
        "metrics = metric.compute()\n",
        "\n",
        "print(metrics[\"precision\"], 1)\n",
        "print(metrics[\"recall\"], 1)\n",
        "print(metrics[\"f1_score\"], 1)\n",
        "\n",
        "metric.reset()\n",
        "\n",
        "logits = jnp.array([0.9, 0.7, 0.2, 0.8, 0.1, 0.3])\n",
        "labels = jnp.array([1, 0, 1, 1, 0, 0])\n",
        "\n",
        "# Expected binary predictions: [1, 1, 0, 1, 0, 0]\n",
        "# TP = 2 (Correct positive predictions: [1, 1])\n",
        "# FP = 1 (False positive prediction: [1])\n",
        "# FN = 1 (False negative prediction: [1])\n",
        "metric.update(None, logits, labels)\n",
        "metrics = metric.compute()\n",
        "\n",
        "expected_precision = 2 / (2 + 1)  # TP / (TP + FP)\n",
        "expected_recall = 2 / (2 + 1)     # TP / (TP + FN)\n",
        "expected_f1 = 2 * (expected_precision * expected_recall) / (expected_precision + expected_recall)\n",
        "\n",
        "print(metrics[\"precision\"], expected_precision)\n",
        "print(metrics[\"recall\"], expected_recall)\n",
        "print(metrics[\"f1_score\"], expected_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlUoD37jprj3",
        "outputId": "539a1b85-33da-4a4a-bf50-69185e044557"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 1\n",
            "1.0 1\n",
            "1.0 1\n",
            "0.6666667 0.6666666666666666\n",
            "0.6666667 0.6666666666666666\n",
            "0.6666666 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up an Optimizer and Metrics"
      ],
      "metadata": {
        "id": "BFME6UD3m88I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Optax for optimizer configuration\n",
        "import optax\n",
        "\n",
        "# Learning rate and momentum for the optimizer\n",
        "learning_rate = 0.005\n",
        "momentum = 0.9\n",
        "\n",
        "# Instantiate the MLP model\n",
        "model = MLP(10, 16, 32, 16, 1, rngs=nnx.Rngs(0))\n",
        "\n",
        "# Set up the optimizer using Adam with the specified learning rate\n",
        "optimizer = nnx.Optimizer(model, optax.adam(learning_rate))\n",
        "\n",
        "# Initialize metrics for tracking training performance\n",
        "metrics = nnx.MultiMetric(\n",
        "    accuracy=CustomAccuracy(),\n",
        "    f1_precision_recall=CustomMetrics(),\n",
        "    loss=nnx.metrics.Average('loss'),  # Tracks the average loss\n",
        ")\n"
      ],
      "metadata": {
        "id": "ASj5AcVZqpXN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Defining Loss, Training, and Evaluation Functions"
      ],
      "metadata": {
        "id": "thvdNah4nV8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(model: MLP, batch):\n",
        "    # Forward pass: Compute logits (raw predictions) using the model\n",
        "    logits = model(batch['features'])\n",
        "\n",
        "    # Compute binary cross-entropy loss for classification\n",
        "    loss = optax.sigmoid_binary_cross_entropy(\n",
        "        logits=logits, labels=batch['labels'].reshape(-1, 1)\n",
        "    ).mean()\n",
        "\n",
        "    # Optionally, use a custom loss function like mean squared error\n",
        "    # loss = (logits - batch['labels'])**2\n",
        "\n",
        "    # Return the computed loss and logits\n",
        "    return loss, logits\n",
        "@nnx.jit\n",
        "def train_step(model: MLP, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
        "    \"\"\"Train for a single step.\"\"\"\n",
        "    # Compute loss and gradients using a differentiable function\n",
        "    grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
        "    (loss, logits), grads = grad_fn(model, batch)\n",
        "\n",
        "    # Update metrics in-place with loss and logits\n",
        "    metrics.update(loss=loss, logits=logits, labels=batch['labels'])\n",
        "\n",
        "    # Apply the computed gradients to update model parameters\n",
        "    optimizer.update(grads)\n",
        "\n",
        "    # Return the loss and logits after applying sigmoid for interpretation\n",
        "    return loss, nnx.sigmoid(logits)\n",
        "@nnx.jit\n",
        "def eval_step(model: MLP, metrics: nnx.MultiMetric, batch):\n",
        "    # Compute loss and logits for the batch\n",
        "    loss, logits = loss_fn(model, batch)\n",
        "\n",
        "    # Update metrics in-place with evaluation results\n",
        "    metrics.update(loss=loss, logits=logits, labels=batch['labels'])\n",
        "\n",
        "    # Return the loss for further aggregation or monitoring\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "HsPjwULJq8GS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Preparation and DataLoader Creation"
      ],
      "metadata": {
        "id": "p6jJmprenxrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch):\n",
        "    # Transpose batch to group features and labels separately\n",
        "    transposed_data = list(zip(*batch))\n",
        "\n",
        "    # Convert labels and features into NumPy arrays\n",
        "    labels = np.array(transposed_data[1])\n",
        "    features = np.array(transposed_data[0])\n",
        "\n",
        "    # Return a dictionary with features and labels\n",
        "    return {\"features\": features, \"labels\": labels}\n",
        "\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [0.7, 0.1, 0.2])\n",
        "\n",
        "train_ds = DataLoader(train_set, batch_size=64, shuffle=True, drop_last=True, collate_fn=custom_collate_fn)\n",
        "val_ds = DataLoader(val_set, batch_size=64, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
        "test_ds = DataLoader(test_set, batch_size=64, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
        "\n",
        "# Fetch a single batch from the training DataLoader\n",
        "batch_data = next(iter(train_ds))\n",
        "imgs = batch_data['features']\n",
        "lbls = batch_data['labels']\n",
        "\n",
        "# Print shapes and data types for verification\n",
        "print(imgs.shape, imgs[0].dtype, lbls.shape, lbls[0].dtype)\n",
        "print(lbls)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fioF1mHarC8_",
        "outputId": "b5ae3b02-5acf-4c47-dd5c-816ace0b85a6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10) float64 (64,) int64\n",
            "[1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint! save model"
      ],
      "metadata": {
        "id": "U4eF72y2q150"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "from orbax.checkpoint.type_handlers import TypeHandler\n",
        "from orbax.checkpoint.type_handlers import register_type_handler\n",
        "from copy import deepcopy\n",
        "\n",
        "def process_and_save_model_state(model, ckpt_dir):\n",
        "    \"\"\"\n",
        "    Processes the model state, modifies the PRNG key, and saves the state to a checkpoint directory.\n",
        "\n",
        "    Args:\n",
        "        model: The model whose state is being processed.\n",
        "        ckpt_dir (str): Directory to save the checkpoint.\n",
        "    \"\"\"\n",
        "    # Retrieve the model's state\n",
        "    state = nnx.state(model)\n",
        "\n",
        "    # Split the model into parameters and state\n",
        "    _, state = nnx.split(model)\n",
        "\n",
        "    # Deep copy the state\n",
        "    state_org = deepcopy(state)\n",
        "\n",
        "    # Display the current state (for inspection)\n",
        "    #nnx.display(state)\n",
        "\n",
        "    # Modify the PRNG key for 'dp1'\n",
        "    prng_key_value = state[\"dp1\"][\"rngs\"][\"default\"][\"key\"].value\n",
        "    state[\"dp1\"][\"rngs\"][\"default\"][\"key\"] = nnx.VariableState(\n",
        "        type=nnx.Param,\n",
        "        value=jax.random.key_data(prng_key_value),\n",
        "        tag='default'\n",
        "    )\n",
        "\n",
        "    # Create a new empty checkpoint directory\n",
        "    ckpt_dir = ocp.test_utils.erase_and_create_empty(ckpt_dir)\n",
        "\n",
        "    # Initialize the checkpointing system\n",
        "    checkpointer = ocp.PyTreeCheckpointer()\n",
        "\n",
        "    # Save the modified state to the checkpoint directory\n",
        "    checkpointer.save(f'{ckpt_dir}/state', state)\n",
        "    #return state_org, prng_key_value\n",
        "\n",
        "# Example usage\n",
        "#model = ...  # Initialize your model\n",
        "ckpt_dir = '/content/my-checkpoints/'  # Specify your checkpoint directory\n",
        "#state_org, prng_key_value = process_and_save_model_state(model, ckpt_dir)\n",
        "process_and_save_model_state(model, ckpt_dir)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jeAzhDPJYSIp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop for Neural Network with Metrics Tracking"
      ],
      "metadata": {
        "id": "HN4uqJhHok23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "\n",
        "def update_metrics_history(metrics_history, prefix, metrics):\n",
        "    \"\"\"\n",
        "    Updates the metrics history dictionary with the computed metrics for a given phase.\n",
        "\n",
        "    Args:\n",
        "        metrics_history (dict): Dictionary to store metrics over epochs.\n",
        "        prefix (str): Prefix for metric keys (e.g., 'train', 'val', 'test').\n",
        "        metrics (object): Metrics object with `compute` method returning metric values.\n",
        "    \"\"\"\n",
        "    for metric, value in metrics.compute().items():\n",
        "        if metric == 'f1_precision_recall':\n",
        "            metrics_history[f'{prefix}_f1_score'].append(value['f1_score'])\n",
        "            metrics_history[f'{prefix}_precision'].append(value['precision'])\n",
        "            metrics_history[f'{prefix}_recall'].append(value['recall'])\n",
        "        else:\n",
        "            metrics_history[f'{prefix}_{metric}'].append(value)\n",
        "\n",
        "def log_metrics(epoch, num_epochs, metrics_history, prefix):\n",
        "    \"\"\"\n",
        "    Logs the metrics for a given phase (train, val) in the current epoch.\n",
        "\n",
        "    Args:\n",
        "        epoch (int): Current epoch number.\n",
        "        num_epochs (int): Total number of epochs.\n",
        "        metrics_history (dict): Dictionary containing historical metrics.\n",
        "        prefix (str): Prefix for metric keys (e.g., 'train', 'val').\n",
        "    \"\"\"\n",
        "    print(\n",
        "        f\"[{prefix}] epoch: {epoch + 1}/{num_epochs}, \"\n",
        "        f\"loss: {metrics_history[f'{prefix}_loss'][-1]:.4f}, \"\n",
        "        f\"accuracy: {metrics_history[f'{prefix}_accuracy'][-1]:.4f}, \"\n",
        "        f\"precision: {metrics_history[f'{prefix}_precision'][-1]:.4f}, \"\n",
        "        f\"recall: {metrics_history[f'{prefix}_recall'][-1]:.4f}, \"\n",
        "        f\"f1_score: {metrics_history[f'{prefix}_f1_score'][-1]:.4f}, \"\n",
        "    )\n",
        "\n",
        "def train_and_evaluate(model, optimizer, train_ds, val_ds, metrics, num_epochs, tracking_metric):\n",
        "    \"\"\"\n",
        "    Trains and evaluates the model while tracking and logging metrics.\n",
        "\n",
        "    Args:\n",
        "        model: Model to train.\n",
        "        optimizer: Optimizer for model training.\n",
        "        train_ds: Training dataset.\n",
        "        val_ds: Validation dataset.\n",
        "        metrics: Metrics object to track performance.\n",
        "        num_epochs (int): Number of training epochs.\n",
        "    \"\"\"\n",
        "    metrics_history = {\n",
        "        'train_loss': [], 'train_accuracy': [], 'train_precision': [],\n",
        "        'train_recall': [], 'train_f1_score': [], 'val_loss': [],\n",
        "        'val_accuracy': [], 'val_precision': [], 'val_recall': [],\n",
        "        'val_f1_score': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        for batch in train_ds:\n",
        "            loss, logits = train_step(model, optimizer, metrics, batch)\n",
        "        update_metrics_history(metrics_history, 'train', metrics)\n",
        "        metrics.reset()  # Reset metrics after training\n",
        "        log_metrics(epoch, num_epochs, metrics_history, 'train')\n",
        "\n",
        "        # Validation phase\n",
        "        for batch in val_ds:\n",
        "            loss = eval_step(model, metrics, batch)\n",
        "        update_metrics_history(metrics_history, 'val', metrics)\n",
        "        metrics.reset()  # Reset metrics after validation\n",
        "        log_metrics(epoch, num_epochs, metrics_history, 'val')\n",
        "        if metrics_history[tracking_metric][-1] == max(metrics_history[tracking_metric]):\n",
        "            print('saving model')\n",
        "            ckpt_dir = '/content/my-checkpoints/'  # Specify your checkpoint directory\n",
        "            process_and_save_model_state(model, ckpt_dir)\n",
        "\n",
        "    return metrics_history\n",
        "\n",
        "# Example usage\n",
        "num_epochs = 5\n",
        "tracking_metric = 'val_accuracy'\n",
        "metrics_history = train_and_evaluate(model, optimizer, train_ds, val_ds, metrics, num_epochs, tracking_metric)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_cxxkNtrH0O",
        "outputId": "127aa26d-4b7a-4acd-eff8-df7d11a80f9c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] epoch: 1/5, loss: 0.1069, accuracy: 0.9592, precision: 0.9669, recall: 0.9590, f1_score: 0.9629, \n",
            "[val] epoch: 1/5, loss: 0.0994, accuracy: 0.9654, precision: 0.9560, recall: 0.9801, f1_score: 0.9679, \n",
            "saving model\n",
            "[train] epoch: 2/5, loss: 0.1039, accuracy: 0.9616, precision: 0.9684, recall: 0.9619, f1_score: 0.9651, \n",
            "[val] epoch: 2/5, loss: 0.1052, accuracy: 0.9632, precision: 0.9586, recall: 0.9727, f1_score: 0.9656, \n",
            "[train] epoch: 3/5, loss: 0.1009, accuracy: 0.9605, precision: 0.9673, recall: 0.9610, f1_score: 0.9641, \n",
            "[val] epoch: 3/5, loss: 0.0988, accuracy: 0.9643, precision: 0.9684, recall: 0.9643, f1_score: 0.9664, \n",
            "[train] epoch: 4/5, loss: 0.1020, accuracy: 0.9610, precision: 0.9684, recall: 0.9609, f1_score: 0.9646, \n",
            "[val] epoch: 4/5, loss: 0.1026, accuracy: 0.9637, precision: 0.9674, recall: 0.9643, f1_score: 0.9658, \n",
            "[train] epoch: 5/5, loss: 0.0966, accuracy: 0.9644, precision: 0.9715, recall: 0.9639, f1_score: 0.9677, \n",
            "[val] epoch: 5/5, loss: 0.1056, accuracy: 0.9587, precision: 0.9592, recall: 0.9633, f1_score: 0.9613, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction and Evaluation Pipeline"
      ],
      "metadata": {
        "id": "L0iX4KVcqTfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "@nnx.jit\n",
        "def pred_step(model: MLP, batch):\n",
        "    logits = model(batch['features'])\n",
        "    return nnx.sigmoid(logits)\n",
        "\n",
        "test_ds = DataLoader(test_set, batch_size=32, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
        "\n",
        "ypred = []  # List to store predicted probabilities\n",
        "label = []  # List to store true labels\n",
        "\n",
        "for test_batch in test_ds:\n",
        "    logits = pred_step(model, test_batch)\n",
        "    ypred.extend(np.ravel(logits))  # Flatten and collect predictions\n",
        "    label.extend(np.ravel(test_batch[\"labels\"]))  # Flatten and collect true labels\n",
        "\n",
        "binary_ypred = np.where(np.array(ypred) > 0.5, 1, 0)\n",
        "\n",
        "accuracy = sum([1 for pred, true in zip(binary_ypred, label) if pred == true]) / len(label)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JdDFipvrj4L",
        "outputId": "fedf3635-5081-42d6-dc28-e4a818d48ce4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing a New Model and Load!"
      ],
      "metadata": {
        "id": "GVyXqnLJrQF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newModel = MLP(10, 16, 32, 16, 1, rngs=nnx.Rngs(0))  # Re-initialize the model\n",
        "abstract_model = nnx.eval_shape(lambda: newModel)  # Evaluate the abstract shape of the model\n",
        "graphdef, abstract_state = nnx.split(abstract_model)  # Split the model into graph and state\n",
        "print('The abstract NNX state (all leaves are abstract arrays):')\n",
        "#nnx.display(abstract_state)  # Uncomment this to display the abstract state (optional for debugging)\n",
        "checkpointer = ocp.PyTreeCheckpointer()\n",
        "state_restored = checkpointer.restore(ckpt_dir + 'state', abstract_state)  # Restore the state from checkpoint\n",
        "#state_restored = checkpointer.restore(optdir+ 'state', abstract_state)  # Restore the state from checkpoint\n",
        "#nnx.display(state_restored['dp1'])  # Optional: Display restored state of dp1\n",
        "\n",
        "#prng_key_value = state[\"dp1\"][\"rngs\"][\"default\"][\"key\"].value  # Access the PRNG key from the original state\n",
        "state_restored[\"dp1\"][\"rngs\"][\"default\"][\"key\"].type(nnx.RngKey)  # Ensure the restored key has the correct type\n",
        "state_restored[\"dp1\"][\"rngs\"][\"default\"][\"key\"].value = jax.random.wrap_key_data(prng_key_value)  # Modify the PRNG key value\n",
        "\n",
        "nnx.display(state_restored['dp1'])  # Display the restored dp1 state\n",
        "nnx.display(state_org['dp1'])  # Display the original dp1 state\n",
        "jax.tree.map(np.testing.assert_array_equal, state_org, state_restored)  # Ensure both states are equal\n",
        "print('NNX State restored: ')\n",
        "#nnx.display(state_restored)  # Uncomment this to display the full restored state\n",
        "\n",
        "newModel = nnx.merge(graphdef, state_restored)  # Merge the graph definition with the restored state\n",
        "optimizer = nnx.Optimizer(newModel, optax.adam(learning_rate))  # Reinitialize the optimizer\n",
        "metrics = nnx.MultiMetric(\n",
        "  loss=nnx.metrics.Average('loss'),  # Initialize metrics for tracking the loss\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "collapsed": true,
        "id": "sIjj6adSeQ88",
        "outputId": "5531f42f-80ef-4db1-bbb3-4d19925f2595"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The abstract NNX state (all leaves are abstract arrays):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/orbax/checkpoint/type_handlers.py:1330: UserWarning: Couldn't find sharding info under RestoreArgs. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file instead of directly from RestoreArgs. Note also that this option is unsafe when restoring on a different topology than the checkpoint was saved with.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'prng_key_value' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-29c00fdea1c7>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#prng_key_value = state[\"dp1\"][\"rngs\"][\"default\"][\"key\"].value  # Access the PRNG key from the original state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mstate_restored\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dp1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rngs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"key\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRngKey\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure the restored key has the correct type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mstate_restored\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dp1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rngs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"key\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_key_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprng_key_value\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Modify the PRNG key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mnnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_restored\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dp1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Display the restored dp1 state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'prng_key_value' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train more if needed"
      ],
      "metadata": {
        "id": "t6s624pmsBwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "#model.train()\n",
        "metrics_history = {\n",
        "  'train_loss': [],\n",
        "  'train_accuracy': [],\n",
        "  'train_precision': [],\n",
        "  'train_recall': [],\n",
        "  'train_f1': [],\n",
        "  'val_loss': [],\n",
        "  'val_accuracy': [],\n",
        "  'val_precision': [],\n",
        "  'val_recall': [],\n",
        "  'val_f1': [],\n",
        "  'test_loss': [],\n",
        "  'test_accuracy': [],\n",
        "  'test_precision': [],\n",
        "  'test_recall': [],\n",
        "  'test_f1': [],\n",
        "}\n",
        "\n",
        "num_epochs = 40  # Number of training epochs\n",
        "for epoch in range(num_epochs):\n",
        "    # Train on each batch in the training dataset\n",
        "    for batch in train_ds:\n",
        "        loss, logits = train_step(model, optimizer, metrics, batch)\n",
        "\n",
        "    # Compute and log training metrics for this epoch\n",
        "    for metric, value in metrics.compute().items():\n",
        "        metrics_history[f'train_{metric}'].append(value)\n",
        "\n",
        "    # Reset metrics for the next epoch\n",
        "    metrics.reset()\n",
        "\n",
        "    # Log training performance\n",
        "    print(\n",
        "        f\"[train] epoch: {epoch + 1}/{num_epochs}, \"\n",
        "        f\"loss: {metrics_history['train_loss'][-1]:.4f}, \"\n",
        "    )\n",
        "\n",
        "# later stuff\n",
        "\"\"\"\n",
        "for batch in val_ds:\n",
        "    loss = eval_step(model, metrics, batch)\n",
        "\n",
        "for metric, value in metrics.compute().items():\n",
        "    metrics_history[f'val_{metric}'].append(value)\n",
        "\n",
        "metrics.reset()\n",
        "print(\n",
        "    f\"[val] epoch: {epoch + 1}/{num_epochs}, \"\n",
        "    f\"loss: {metrics_history['val_loss'][-1]:.4f}, \"\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"[train] epoch: {epoch + 1}/{num_epochs}, \"\n",
        "    f\"loss: {metrics_history['train_loss'][-1]:.4f}, \"\n",
        "    f\"accuracy: {metrics_history['train_accuracy'][-1]:.2f}\"\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "O8Ukn5kWrwut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validate saved model"
      ],
      "metadata": {
        "id": "7qZ0YMvQsI5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@nnx.jit\n",
        "def pred_step(model: MLP, batch):\n",
        "    logits = model(batch['features'])\n",
        "    return nnx.sigmoid(logits)\n",
        "\n",
        "test_ds = DataLoader(test_set, batch_size=32, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
        "\n",
        "ypred = []  # List to store predicted probabilities\n",
        "label = []  # List to store true labels\n",
        "\n",
        "for test_batch in test_ds:\n",
        "    logits = pred_step(newModel, test_batch)\n",
        "    ypred.extend(np.ravel(logits))  # Flatten and collect predictions\n",
        "    label.extend(np.ravel(test_batch[\"labels\"]))  # Flatten and collect true labels\n",
        "\n",
        "binary_ypred = np.where(np.array(ypred) > 0.5, 1, 0)\n",
        "\n",
        "accuracy = sum([1 for pred, true in zip(binary_ypred, label) if pred == true]) / len(label)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "jqlRLOx02910"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}