{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/7ftQekZN1t3+JzhsxwRW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohsenh17/jaxLearning/blob/main/flax/flaxCheckpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUAfhJeb-vgD",
        "outputId": "e3f2e79a-f7a0-4102-9107-93f9075edf7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: orbax in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.35)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax) (1.1.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax) (0.2.3)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax) (0.6.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.67)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax) (13.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax) (6.0.2)\n",
            "Requirement already satisfied: jaxlib<=0.4.35,>=0.4.34 in /usr/local/lib/python3.10/dist-packages (from jax) (0.4.35)\n",
            "Requirement already satisfied: ml-dtypes>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from jax) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax) (1.13.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.4.0)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.10.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (4.25.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (2.18.0)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (0.1.87)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->flax) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (3.20.2)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade flax orbax jax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "from flax import nnx\n",
        "import jax.numpy as jnp\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import orbax.checkpoint as ocp\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import io\n",
        "\n"
      ],
      "metadata": {
        "id": "JFO7NNqQ_Dtc"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate a dataset with 100 samples, 10 features, 5 informative, 5 redundant, and 2 classes\n",
        "X, y = make_classification(n_samples=256, n_features=10, n_informative=8,\n",
        "                          n_classes=2, random_state=42)\n",
        "df = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
        "df['Class'] = y\n",
        "csv_data = df.to_csv(index=True)\n"
      ],
      "metadata": {
        "id": "W4I2hnqUodtF"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, dataset, transform=None, target_transform=None):\n",
        "        completeDF = pd.read_csv(dataset, index_col=0)\n",
        "        self.labels = pd.DataFrame(completeDF['Class'])\n",
        "        features_raw = pd.DataFrame(completeDF.drop('Class', axis=1))\n",
        "        #self.features = pd.DataFrame(completeDF.drop('Class', axis=1))\n",
        "        scaler = MinMaxScaler()\n",
        "        self.features = pd.DataFrame(scaler.fit_transform(features_raw))\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = np.array(self.features.iloc[idx, :])\n",
        "        label = self.labels.iloc[idx, 0]\n",
        "        if self.transform:\n",
        "            features = self.transform(features)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return features, label"
      ],
      "metadata": {
        "id": "ZBPFELboo4e1"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomImageDataset(dataset=io.StringIO(csv_data))\n",
        "#dataset = CustomImageDataset(dataset=\"dataset/riceClassification.csv\")\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [.7, 0.1,0.2])\n",
        "data_loader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
        "\n",
        "for features, labels in data_loader:\n",
        "    print(\"Batch of features has shape: \",features.shape)\n",
        "    print(\"Batch of labels has shape: \", labels.shape)\n",
        "    print(features)\n",
        "    print(labels)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s3fFrv-otNR",
        "outputId": "1dfebc8b-1df6-4d45-da29-6fae451b7ee5"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch of features has shape:  torch.Size([4, 10])\n",
            "Batch of labels has shape:  torch.Size([4])\n",
            "tensor([[0.6415, 0.3986, 0.3478, 0.3950, 0.2933, 0.2386, 0.3254, 0.7682, 0.4544,\n",
            "         0.6269],\n",
            "        [0.5566, 0.5970, 0.3363, 0.5311, 0.5245, 0.3408, 0.7131, 0.6877, 0.4067,\n",
            "         0.4531],\n",
            "        [0.4134, 0.6072, 0.2426, 0.4445, 0.2696, 0.3440, 0.2871, 0.4632, 0.5598,\n",
            "         0.5877],\n",
            "        [0.6251, 0.7010, 0.6922, 0.5333, 0.7998, 0.2144, 0.6096, 0.5264, 0.4557,\n",
            "         0.4470]], dtype=torch.float64)\n",
            "tensor([1, 0, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nnx.Module):\n",
        "    def __init__(self, din, dm1, dm2, dm3, num_classes: int, rngs: nnx.Rngs):\n",
        "      self.linear1 = nnx.Linear(10, 16, rngs=rngs)\n",
        "      self.dp1 = nnx.Dropout(rate=0.4, rngs=rngs)\n",
        "      self.bn1 = nnx.BatchNorm(16, rngs=rngs)\n",
        "      \"\"\"self.linear2 = nnx.Linear(16, 32, rngs=rngs)\n",
        "      self.bn2 = nnx.BatchNorm(32, rngs=rngs)\n",
        "      self.linear3 = nnx.Linear(32, 16, rngs=rngs)\n",
        "      self.bn3 = nnx.BatchNorm(16, rngs=rngs)\n",
        "      self.linear4 = nnx.Linear(16, 1, rngs=rngs)\"\"\"\n",
        "\n",
        "\n",
        "    def __call__(self, x):\n",
        "      x = self.linear1(x)\n",
        "      x = nnx.gelu(x)\n",
        "      x = self.dp1(x)\n",
        "      x = self.bn1(x)\n",
        "      \"\"\"#x = self.dropout(x)\n",
        "      x = self.linear2(x)\n",
        "      x = nnx.gelu(x)\n",
        "      x = self.bn2(x)\n",
        "      #x = self.dropout(x)\n",
        "      x = self.linear3(x)\n",
        "      x = nnx.gelu(x)\n",
        "      x = self.bn3(x)\"\"\"\n",
        "      return nnx.sigmoid(x)\n",
        "\n",
        "# Instantiate and test the model\n",
        "model = MLP(10, 16, 32, 16, 1, rngs=nnx.Rngs(0))\n",
        "#y = model(x=jnp.ones((3, 10)))\n",
        "\n",
        "#nnx.display(model)\n",
        "\n",
        "#model = MLP([2, 4], 1, rngs=nnx.Rngs(0))\n",
        "y = model(x=jnp.ones((3, 10)))\n",
        "\n",
        "nnx.display(y)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C2PTOR3_Abz",
        "outputId": "e6f17bda-7896-4a5c-9e49-91dcce963057"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5        0.8028934  0.5        0.8043662  0.33058918 0.33053228\n",
            "  0.33028775 0.33034152 0.5        0.19563586 0.8044264  0.33030894\n",
            "  0.6697085  0.3302991  0.6696849  0.3302848 ]\n",
            " [0.5        0.33131608 0.5        0.3302831  0.33058918 0.80401146\n",
            "  0.80435956 0.33034152 0.5        0.66971546 0.33024082 0.8043294\n",
            "  0.6697085  0.80434346 0.19567941 0.8043637 ]\n",
            " [0.5        0.33131608 0.5        0.3302831  0.8039304  0.33053228\n",
            "  0.33028775 0.80428296 0.5        0.66971546 0.33024082 0.33030894\n",
            "  0.19564575 0.3302991  0.6696849  0.3302848 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optax\n",
        "learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "\n",
        "model = MLP(10, 16, 32, 16, 1, rngs=nnx.Rngs(0))\n",
        "optimizer = nnx.Optimizer(model, optax.adam(learning_rate))\n",
        "metrics = nnx.MultiMetric(\n",
        "  loss=nnx.metrics.Average('loss'),\n",
        ")"
      ],
      "metadata": {
        "id": "ASj5AcVZqpXN"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def loss_fn(model: MLP, batch):\n",
        "  logits = model(batch['features'])\n",
        "  loss = optax.sigmoid_binary_cross_entropy(\n",
        "    logits=logits, labels=batch['labels'].reshape(-1, 1)\n",
        "  ).mean()\n",
        "  #loss = (logits - batch['labels'])**2\n",
        "  #print(logits.pval)\n",
        "  return loss, logits\n",
        "\n",
        "@nnx.jit\n",
        "def train_step(model: MLP, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
        "  \"\"\"Train for a single step.\"\"\"\n",
        "  grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
        "  (loss, logits), grads = grad_fn(model, batch)\n",
        "\n",
        "  metrics.update(loss=loss, logits=logits, labels=batch['labels'])  # In-place updates.\n",
        "  optimizer.update(grads)  # In-place updates.\n",
        "  return loss, logits\n",
        "\n",
        "@nnx.jit\n",
        "def eval_step(model: MLP, metrics: nnx.MultiMetric, batch):\n",
        "  loss, logits = loss_fn(model, batch)\n",
        "  metrics.update(loss=loss, logits=logits, labels=batch['labels'])  # In-place updates.\n",
        "  return loss"
      ],
      "metadata": {
        "id": "HsPjwULJq8GS"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch):\n",
        "    transposed_data = list(zip(*batch))\n",
        "\n",
        "    labels =  np.array(transposed_data[1])\n",
        "    features = np.array(transposed_data[0])\n",
        "\n",
        "    return {\"features\":features, \"labels\":labels}\n",
        "\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [.7, 0.1,0.2])\n",
        "\n",
        "train_ds = DataLoader(train_set, batch_size=64, shuffle=True, drop_last=True, collate_fn=custom_collate_fn)\n",
        "val_set = DataLoader(val_set, batch_size=4, shuffle=True, drop_last=True, collate_fn=custom_collate_fn)\n",
        "test_ds = DataLoader(test_set, batch_size=4, shuffle=True, drop_last=True, collate_fn=custom_collate_fn)\n",
        "\n",
        "# test\n",
        "batch_data = next(iter(train_ds))\n",
        "imgs = batch_data['features']\n",
        "lbls = batch_data['labels']\n",
        "print(imgs.shape, imgs[0].dtype, lbls.shape, lbls[0].dtype)\n",
        "print(lbls)\n",
        "\n",
        "#loss = train_step(model, optimizer, metrics, batch_data)\n",
        "loss, logits = loss_fn(model, batch_data)\n",
        "print(loss.shape, logits.shape)\n",
        "print(f'{loss = }')\n",
        "#print(f'{logits = }')\n",
        "print(f'{optimizer.step.value = }')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fioF1mHarC8_",
        "outputId": "407a5999-42e5-46f3-a88b-65f9bdccd1c3"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10) float64 (64,) int64\n",
            "[0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1\n",
            " 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0]\n",
            "() (64, 16)\n",
            "loss = Array(0.72493005, dtype=float32)\n",
            "optimizer.step.value = Array(0, dtype=uint32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import orbax.checkpoint as ocp\n",
        "ckpt_dir = ocp.test_utils.erase_and_create_empty('/content/my-checkpoints/')\n",
        "metrics_history = {\n",
        "  'train_loss': [],\n",
        "  'train_accuracy': [],\n",
        "  'train_precision': [],\n",
        "  'train_recall': [],\n",
        "  'train_f1': [],\n",
        "  'val_loss': [],\n",
        "  'val_accuracy': [],\n",
        "  'val_precision': [],\n",
        "  'val_recall': [],\n",
        "  'val_f1': [],\n",
        "  'test_loss': [],\n",
        "  'test_accuracy': [],\n",
        "  'test_precision': [],\n",
        "  'test_recall': [],\n",
        "  'test_f1': [],\n",
        "}\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_ds:\n",
        "      loss, logits = train_step(model, optimizer, metrics, batch)\n",
        "\n",
        "    for metric, value in metrics.compute().items():\n",
        "      metrics_history[f'train_{metric}'].append(value)\n",
        "\n",
        "    metrics.reset()\n",
        "    print(\n",
        "      f\"[train] epoch: {epoch}, \"\n",
        "      f\"loss: {metrics_history['train_loss'][-1]}, \"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_cxxkNtrH0O",
        "outputId": "8a90dd42-e104-494d-9d18-a1e3fc163d45"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] epoch: 0, loss: 0.7277255058288574, \n",
            "[train] epoch: 1, loss: 0.7444443106651306, \n",
            "[train] epoch: 2, loss: 0.7387948036193848, \n",
            "[train] epoch: 3, loss: 0.7119072675704956, \n",
            "[train] epoch: 4, loss: 0.7009329199790955, \n",
            "[train] epoch: 5, loss: 0.7275881767272949, \n",
            "[train] epoch: 6, loss: 0.7228589057922363, \n",
            "[train] epoch: 7, loss: 0.7303940057754517, \n",
            "[train] epoch: 8, loss: 0.7135761976242065, \n",
            "[train] epoch: 9, loss: 0.7185161113739014, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() # Switch to evaluation mode.\n",
        "\n",
        "@nnx.jit\n",
        "def pred_step(model: MLP, batch):\n",
        "  logits = model(batch['features'])\n",
        "  return logits\n",
        "\n",
        "test_ds = DataLoader(test_set, batch_size=32, shuffle=False, drop_last=True, collate_fn=custom_collate_fn)\n",
        "\n",
        "ypred = []\n",
        "label = []\n",
        "for test_batch in test_ds:\n",
        "  logits = pred_step(model, test_batch)\n",
        "  #print(np.ravel(logits))\n",
        "  #print(np.ravel(logits))\n",
        "  #break\n",
        "  ypred.extend(np.ravel(logits))\n",
        "  label.extend(np.ravel(test_batch[\"labels\"]))\n",
        "  #print(logits, test_batch[\"labels\"])\n",
        "  #break\n",
        "binary_ypred = np.where(np.array(ypred) > 0.5, 1, 0)\n",
        "print(len(label), sum(label))\n",
        "accuracy = sum([1 for pred, true in zip(binary_ypred, label) if pred == true]) / len(label)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JdDFipvrj4L",
        "outputId": "fdda10ba-b115-4ae4-d163-65d72363d81c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32 17\n",
            "Accuracy: 0.4688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "from orbax.checkpoint.type_handlers import TypeHandler\n",
        "from orbax.checkpoint.type_handlers import register_type_handler\n",
        "\n",
        "state = nnx.state(model)\n",
        "_, state = nnx.split(model)\n",
        "nnx.display(state['dp1'])\n",
        "prng_key_value = state[\"dp1\"][\"rngs\"][\"default\"][\"key\"].value\n",
        "#print(prng_key_value.dtype)\n",
        "state[\"dp1\"][\"rngs\"][\"default\"][\"key\"] = nnx.VariableState(\n",
        "    type=nnx.Param, value=jax.random.key_data(prng_key_value), tag='default'\n",
        ")\n",
        "nnx.display(state)\n",
        "# Save the parameters\n",
        "ckpt_dir = ocp.test_utils.erase_and_create_empty('/content/my-checkpoints/')\n",
        "checkpointer = ocp.PyTreeCheckpointer()\n",
        "checkpointer.save('/content/my-checkpoints/state', state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jeAzhDPJYSIp",
        "outputId": "45afaae3-5a88-4b23-b6e2-c19ccaeb90de"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State({\n",
            "  'rngs': {\n",
            "    'default': {\n",
            "      'count': VariableState(\n",
            "        type=RngCount,\n",
            "        value=Array(25, dtype=uint32),\n",
            "        tag='default'\n",
            "      ),\n",
            "      'key': VariableState(\n",
            "        type=RngKey,\n",
            "        value=Array((), dtype=key<fry>) overlaying:\n",
            "        [0 0],\n",
            "        tag='default'\n",
            "      )\n",
            "    }\n",
            "  }\n",
            "})\n",
            "State({\n",
            "  'bn1': {\n",
            "    'bias': VariableState(\n",
            "      type=Param,\n",
            "      value=Array([-0.01851453, -0.01809671, -0.01805194, -0.01850327, -0.01832869,\n",
            "             -0.01856782, -0.01792235, -0.01848269, -0.01820147, -0.01813109,\n",
            "             -0.01774389, -0.01871058, -0.01857002, -0.01832548, -0.01838941,\n",
            "             -0.01777863], dtype=float32)\n",
            "    ),\n",
            "    'mean': VariableState(\n",
            "      type=BatchStat,\n",
            "      value=Array([-2.9075747e-02, -3.0570619e-02, -7.8527381e-05, -1.8928114e-02,\n",
            "             -3.1981084e-02,  7.6465530e-04,  1.1133681e-02, -9.8525900e-03,\n",
            "              2.2586300e-03, -1.9554241e-02,  3.5659537e-02, -1.5808607e-02,\n",
            "             -1.6209841e-02, -2.9383343e-02, -1.0688387e-02, -2.2975601e-02],      dtype=float32)\n",
            "    ),\n",
            "    'scale': VariableState(\n",
            "      type=Param,\n",
            "      value=Array([0.98555857, 0.98480165, 0.986181  , 0.98448235, 0.9858603 ,\n",
            "             1.0173557 , 0.98315984, 0.98369414, 0.9852811 , 0.98390937,\n",
            "             0.98255885, 0.98194635, 0.9835817 , 0.9844464 , 0.98649657,\n",
            "             1.0085167 ], dtype=float32)\n",
            "    ),\n",
            "    'var': VariableState(\n",
            "      type=BatchStat,\n",
            "      value=Array([0.81271833, 0.81293666, 0.8132283 , 0.8116648 , 0.8130868 ,\n",
            "             0.81231046, 0.8124384 , 0.8125327 , 0.81228054, 0.8120268 ,\n",
            "             0.8187913 , 0.81118065, 0.8113478 , 0.8127761 , 0.8104353 ,\n",
            "             0.8117715 ], dtype=float32)\n",
            "    )\n",
            "  },\n",
            "  'dp1': {\n",
            "    'rngs': {\n",
            "      'default': {\n",
            "        'count': VariableState(\n",
            "          type=RngCount,\n",
            "          value=Array(25, dtype=uint32),\n",
            "          tag='default'\n",
            "        ),\n",
            "        'key': VariableState(\n",
            "          type=Param,\n",
            "          value=Array([0, 0], dtype=uint32),\n",
            "          tag='default'\n",
            "        )\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  'linear1': {\n",
            "    'bias': VariableState(\n",
            "      type=Param,\n",
            "      value=Array([ 0.01873128,  0.0161241 ,  0.00665042,  0.00719349,  0.01850869,\n",
            "              0.01220806,  0.00836163,  0.00386624,  0.01125085, -0.00211451,\n",
            "             -0.00517815, -0.01675176,  0.00393707, -0.01907261,  0.00402733,\n",
            "              0.01964151], dtype=float32)\n",
            "    ),\n",
            "    'kernel': VariableState(\n",
            "      type=Param,\n",
            "      value=Array([[-0.36130852,  0.43739098,  0.65184647, -0.5716997 , -0.23816393,\n",
            "               0.07052835,  0.23369727,  0.21715292, -0.3347722 ,  0.46668506,\n",
            "              -0.5496262 ,  0.18448472, -0.11428127, -0.45176935,  0.39749393,\n",
            "              -0.06534295],\n",
            "             [-0.02910572, -0.3941933 , -0.23477003, -0.54760665,  0.13087323,\n",
            "              -0.4454845 ,  0.38816014, -0.31646752, -0.49287885, -0.46445146,\n",
            "               0.41619307,  0.07832439,  0.07127457, -0.7186421 ,  0.03989064,\n",
            "               0.16117315],\n",
            "             [ 0.10701095,  0.04284155, -0.39041433, -0.07985075, -0.09230489,\n",
            "              -0.19906378,  0.46578437,  0.28389072,  0.27531686,  0.57153606,\n",
            "               0.14993776, -0.0864437 , -0.04555903,  0.03892807, -0.27757218,\n",
            "              -0.12396224],\n",
            "             [-0.3857746 , -0.05291703, -0.5049231 ,  0.13092822, -0.12525886,\n",
            "               0.53019446, -0.3044569 ,  0.3854477 , -0.3730958 , -0.385236  ,\n",
            "               0.4424237 ,  0.19448458, -0.6662595 ,  0.22528765,  0.07638676,\n",
            "              -0.29037198],\n",
            "             [-0.5127645 , -0.5709684 , -0.25398335,  0.15847793, -0.24722046,\n",
            "               0.03129697, -0.1696281 , -0.26695085,  0.43854693,  0.20166533,\n",
            "               0.1348248 , -0.2637337 , -0.06812204,  0.22720563, -0.22838593,\n",
            "              -0.3834764 ],\n",
            "             [-0.08890271, -0.36223274,  0.33681837, -0.00089666, -0.3878891 ,\n",
            "               0.05998706, -0.01799539,  0.360151  ,  0.12300293, -0.56737924,\n",
            "               0.20496964, -0.41062248,  0.15070297, -0.16468935, -0.12085753,\n",
            "              -0.02638275],\n",
            "             [-0.43492404, -0.31597146,  0.44217697, -0.11609237, -0.4164461 ,\n",
            "              -0.4711529 ,  0.12408851,  0.2803335 ,  0.24213353, -0.09041101,\n",
            "              -0.12732157,  0.2712681 ,  0.23161545,  0.4548342 ,  0.03303704,\n",
            "              -0.06728735],\n",
            "             [ 0.24492958, -0.13367158, -0.2236128 , -0.0257007 ,  0.09420557,\n",
            "               0.5172316 , -0.22909673, -0.1991436 ,  0.3337988 , -0.35034186,\n",
            "              -0.07714276, -0.69204444, -0.31187674, -0.48977622,  0.00737389,\n",
            "               0.25184566],\n",
            "             [-0.08461408, -0.36522853,  0.20987281,  0.35540307,  0.04779782,\n",
            "              -0.02514913, -0.17185043, -0.5687579 , -0.3710418 , -0.11417563,\n",
            "               0.33045068,  0.2025762 , -0.03751536, -0.0646125 , -0.14810671,\n",
            "              -0.24122381],\n",
            "             [-0.47420445, -0.25945276, -0.23606142,  0.06843606, -0.4303836 ,\n",
            "              -0.15073739, -0.00721962, -0.5026073 ,  0.05359955,  0.06013818,\n",
            "              -0.08098184, -0.02415744,  0.25767002, -0.39014465, -0.14766295,\n",
            "               0.05732232]], dtype=float32)\n",
            "    )\n",
            "  }\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abstract_model = nnx.eval_shape(lambda: model)\n",
        "graphdef, abstract_state = nnx.split(abstract_model)\n",
        "print('The abstract NNX state (all leaves are abstract arrays):')\n",
        "nnx.display(abstract_state)\n",
        "\n",
        "state_restored = checkpointer.restore(ckpt_dir / 'state', abstract_state)\n",
        "nnx.display(state_restored['dp1'])\n",
        "prng_key_value = state[\"dp1\"][\"rngs\"][\"default\"][\"key\"].value\n",
        "state_restored[\"dp1\"][\"rngs\"][\"default\"][\"key\"] = nnx.VariableState(\n",
        "    type=nnx.Param, value=jax.random.wrap_key_data(prng_key_value), tag='default'\n",
        ")\n",
        "\n",
        "#jax.tree.map(np.testing.assert_array_equal, state, state_restored)\n",
        "print('NNX State restored: ')\n",
        "nnx.display(state_restored)\n",
        "\n",
        "# The model is now good to use!\n",
        "model = nnx.merge(graphdef, state_restored)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sIjj6adSeQ88",
        "outputId": "00d9e461-1730-4d9b-9508-e152165b23fb"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The abstract NNX state (all leaves are abstract arrays):\n",
            "State({\n",
            "  'bn1': {\n",
            "    'bias': VariableState(\n",
            "      type=Param,\n",
            "      value=ShapeDtypeStruct(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    'mean': VariableState(\n",
            "      type=BatchStat,\n",
            "      value=ShapeDtypeStruct(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    'scale': VariableState(\n",
            "      type=Param,\n",
            "      value=ShapeDtypeStruct(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    'var': VariableState(\n",
            "      type=BatchStat,\n",
            "      value=ShapeDtypeStruct(shape=(16,), dtype=float32)\n",
            "    )\n",
            "  },\n",
            "  'dp1': {\n",
            "    'rngs': {\n",
            "      'default': {\n",
            "        'count': VariableState(\n",
            "          type=RngCount,\n",
            "          value=ShapeDtypeStruct(shape=(), dtype=uint32),\n",
            "          tag='default'\n",
            "        ),\n",
            "        'key': VariableState(\n",
            "          type=Param,\n",
            "          value=ShapeDtypeStruct(shape=(), dtype=key<fry>),\n",
            "          tag='default'\n",
            "        )\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  'linear1': {\n",
            "    'bias': VariableState(\n",
            "      type=Param,\n",
            "      value=ShapeDtypeStruct(shape=(16,), dtype=float32)\n",
            "    ),\n",
            "    'kernel': VariableState(\n",
            "      type=Param,\n",
            "      value=ShapeDtypeStruct(shape=(10, 16), dtype=float32)\n",
            "    )\n",
            "  }\n",
            "})\n",
            "State({\n",
            "  'rngs': {\n",
            "    'default': {\n",
            "      'count': VariableState(\n",
            "        type=RngCount,\n",
            "        value=Array(25, dtype=uint32),\n",
            "        tag='default'\n",
            "      ),\n",
            "      'key': VariableState(\n",
            "        type=Param,\n",
            "        value=Array([0, 0], dtype=uint32),\n",
            "        tag='default'\n",
            "      )\n",
            "    }\n",
            "  }\n",
            "})\n",
            "NNX State restored: \n",
            "State({\n",
            "  'bn1': {\n",
            "    'bias': VariableState(\n",
            "      type=Param,\n",
            "      value=Array([-0.01851453, -0.01809671, -0.01805194, -0.01850327, -0.01832869,\n",
            "             -0.01856782, -0.01792235, -0.01848269, -0.01820147, -0.01813109,\n",
            "             -0.01774389, -0.01871058, -0.01857002, -0.01832548, -0.01838941,\n",
            "             -0.01777863], dtype=float32)\n",
            "    ),\n",
            "    'mean': VariableState(\n",
            "      type=BatchStat,\n",
            "      value=Array([-2.9075747e-02, -3.0570619e-02, -7.8527381e-05, -1.8928114e-02,\n",
            "             -3.1981084e-02,  7.6465530e-04,  1.1133681e-02, -9.8525900e-03,\n",
            "              2.2586300e-03, -1.9554241e-02,  3.5659537e-02, -1.5808607e-02,\n",
            "             -1.6209841e-02, -2.9383343e-02, -1.0688387e-02, -2.2975601e-02],      dtype=float32)\n",
            "    ),\n",
            "    'scale': VariableState(\n",
            "      type=Param,\n",
            "      value=Array([0.98555857, 0.98480165, 0.986181  , 0.98448235, 0.9858603 ,\n",
            "             1.0173557 , 0.98315984, 0.98369414, 0.9852811 , 0.98390937,\n",
            "             0.98255885, 0.98194635, 0.9835817 , 0.9844464 , 0.98649657,\n",
            "             1.0085167 ], dtype=float32)\n",
            "    ),\n",
            "    'var': VariableState(\n",
            "      type=BatchStat,\n",
            "      value=Array([0.81271833, 0.81293666, 0.8132283 , 0.8116648 , 0.8130868 ,\n",
            "             0.81231046, 0.8124384 , 0.8125327 , 0.81228054, 0.8120268 ,\n",
            "             0.8187913 , 0.81118065, 0.8113478 , 0.8127761 , 0.8104353 ,\n",
            "             0.8117715 ], dtype=float32)\n",
            "    )\n",
            "  },\n",
            "  'dp1': {\n",
            "    'rngs': {\n",
            "      'default': {\n",
            "        'count': VariableState(\n",
            "          type=RngCount,\n",
            "          value=Array(25, dtype=uint32),\n",
            "          tag='default'\n",
            "        ),\n",
            "        'key': VariableState(\n",
            "          type=Param,\n",
            "          value=Array((), dtype=key<fry>) overlaying:\n",
            "          [0 0],\n",
            "          tag='default'\n",
            "        )\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  'linear1': {\n",
            "    'bias': VariableState(\n",
            "      type=Param,\n",
            "      value=Array([ 0.01873128,  0.0161241 ,  0.00665042,  0.00719349,  0.01850869,\n",
            "              0.01220806,  0.00836163,  0.00386624,  0.01125085, -0.00211451,\n",
            "             -0.00517815, -0.01675176,  0.00393707, -0.01907261,  0.00402733,\n",
            "              0.01964151], dtype=float32)\n",
            "    ),\n",
            "    'kernel': VariableState(\n",
            "      type=Param,\n",
            "      value=Array([[-0.36130852,  0.43739098,  0.65184647, -0.5716997 , -0.23816393,\n",
            "               0.07052835,  0.23369727,  0.21715292, -0.3347722 ,  0.46668506,\n",
            "              -0.5496262 ,  0.18448472, -0.11428127, -0.45176935,  0.39749393,\n",
            "              -0.06534295],\n",
            "             [-0.02910572, -0.3941933 , -0.23477003, -0.54760665,  0.13087323,\n",
            "              -0.4454845 ,  0.38816014, -0.31646752, -0.49287885, -0.46445146,\n",
            "               0.41619307,  0.07832439,  0.07127457, -0.7186421 ,  0.03989064,\n",
            "               0.16117315],\n",
            "             [ 0.10701095,  0.04284155, -0.39041433, -0.07985075, -0.09230489,\n",
            "              -0.19906378,  0.46578437,  0.28389072,  0.27531686,  0.57153606,\n",
            "               0.14993776, -0.0864437 , -0.04555903,  0.03892807, -0.27757218,\n",
            "              -0.12396224],\n",
            "             [-0.3857746 , -0.05291703, -0.5049231 ,  0.13092822, -0.12525886,\n",
            "               0.53019446, -0.3044569 ,  0.3854477 , -0.3730958 , -0.385236  ,\n",
            "               0.4424237 ,  0.19448458, -0.6662595 ,  0.22528765,  0.07638676,\n",
            "              -0.29037198],\n",
            "             [-0.5127645 , -0.5709684 , -0.25398335,  0.15847793, -0.24722046,\n",
            "               0.03129697, -0.1696281 , -0.26695085,  0.43854693,  0.20166533,\n",
            "               0.1348248 , -0.2637337 , -0.06812204,  0.22720563, -0.22838593,\n",
            "              -0.3834764 ],\n",
            "             [-0.08890271, -0.36223274,  0.33681837, -0.00089666, -0.3878891 ,\n",
            "               0.05998706, -0.01799539,  0.360151  ,  0.12300293, -0.56737924,\n",
            "               0.20496964, -0.41062248,  0.15070297, -0.16468935, -0.12085753,\n",
            "              -0.02638275],\n",
            "             [-0.43492404, -0.31597146,  0.44217697, -0.11609237, -0.4164461 ,\n",
            "              -0.4711529 ,  0.12408851,  0.2803335 ,  0.24213353, -0.09041101,\n",
            "              -0.12732157,  0.2712681 ,  0.23161545,  0.4548342 ,  0.03303704,\n",
            "              -0.06728735],\n",
            "             [ 0.24492958, -0.13367158, -0.2236128 , -0.0257007 ,  0.09420557,\n",
            "               0.5172316 , -0.22909673, -0.1991436 ,  0.3337988 , -0.35034186,\n",
            "              -0.07714276, -0.69204444, -0.31187674, -0.48977622,  0.00737389,\n",
            "               0.25184566],\n",
            "             [-0.08461408, -0.36522853,  0.20987281,  0.35540307,  0.04779782,\n",
            "              -0.02514913, -0.17185043, -0.5687579 , -0.3710418 , -0.11417563,\n",
            "               0.33045068,  0.2025762 , -0.03751536, -0.0646125 , -0.14810671,\n",
            "              -0.24122381],\n",
            "             [-0.47420445, -0.25945276, -0.23606142,  0.06843606, -0.4303836 ,\n",
            "              -0.15073739, -0.00721962, -0.5026073 ,  0.05359955,  0.06013818,\n",
            "              -0.08098184, -0.02415744,  0.25767002, -0.39014465, -0.14766295,\n",
            "               0.05732232]], dtype=float32)\n",
            "    )\n",
            "  }\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "\n",
        "metrics_history = {\n",
        "  'train_loss': [],\n",
        "  'train_accuracy': [],\n",
        "  'train_precision': [],\n",
        "  'train_recall': [],\n",
        "  'train_f1': [],\n",
        "  'val_loss': [],\n",
        "  'val_accuracy': [],\n",
        "  'val_precision': [],\n",
        "  'val_recall': [],\n",
        "  'val_f1': [],\n",
        "  'test_loss': [],\n",
        "  'test_accuracy': [],\n",
        "  'test_precision': [],\n",
        "  'test_recall': [],\n",
        "  'test_f1': [],\n",
        "}\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_ds:\n",
        "      loss, logits = train_step(model, optimizer, metrics, batch)\n",
        "\n",
        "    for metric, value in metrics.compute().items():\n",
        "      metrics_history[f'train_{metric}'].append(value)\n",
        "\n",
        "    metrics.reset()\n",
        "    print(\n",
        "      f\"[train] epoch: {epoch}, \"\n",
        "      f\"loss: {metrics_history['train_loss'][-1]}, \"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "O8Ukn5kWrwut",
        "outputId": "361e27f1-23b0-4567-8b55-f57e7a896ea2"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "grad requires real- or complex-valued inputs (input dtype that is a sub-dtype of np.inexact), but got key<fry>. If you want to use Boolean- or integer-valued inputs, use vjp or set allow_int to True.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-9b660590b5e9>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/graph.py\u001b[0m in \u001b[0;36mupdate_context_manager_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_context_manager_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdate_context_manager_wrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/transforms/compilation.py\u001b[0m in \u001b[0;36mjit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0mctxtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jit'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     )\n\u001b[0;32m--> 345\u001b[0;31m     pure_args_out, pure_kwargs_out, pure_out = jitted_fn(\n\u001b[0m\u001b[1;32m    346\u001b[0m       \u001b[0;34m*\u001b[0m\u001b[0mpure_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpure_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     )\n",
            "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/transforms/compilation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *pure_args, **pure_kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpure_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpure_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctxtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0margs_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_non_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-c27ddb86877b>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, optimizer, metrics, batch)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;34m\"\"\"Train for a single step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mgrad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# In-place updates.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/graph.py\u001b[0m in \u001b[0;36mupdate_context_manager_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_context_manager_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdate_context_manager_wrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/nnx/transforms/autodiff.py\u001b[0m in \u001b[0;36mgrad_wrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'grad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnondiff_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m       \u001b[0mfn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradded_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpure_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_check_input_dtype_revderiv\u001b[0;34m(name, holomorphic, allow_int, x)\u001b[0m\n\u001b[1;32m    499\u001b[0m       dtypes.issubdtype(aval.dtype, np.bool_)):\n\u001b[1;32m    500\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_int\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m       raise TypeError(f\"{name} requires real- or complex-valued inputs (input dtype \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                       \u001b[0;34mf\"that is a sub-dtype of np.inexact), but got {aval.dtype.name}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                       \u001b[0;34m\"If you want to use Boolean- or integer-valued inputs, use vjp \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: grad requires real- or complex-valued inputs (input dtype that is a sub-dtype of np.inexact), but got key<fry>. If you want to use Boolean- or integer-valued inputs, use vjp or set allow_int to True."
          ]
        }
      ]
    }
  ]
}